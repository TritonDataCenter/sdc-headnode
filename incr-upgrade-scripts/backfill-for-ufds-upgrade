#!/usr/bin/env node
/**
 * -*- mode: js -*-
 * vim: set filetype=javascript :
 *
 * Copyright (c) 2013, Joyent, Inc. All rights reserved.
 *
 *
 * Backfill a bucket in moray with data for a new index column.
 *
 * When a new field is to be indexed in a Moray bucket, a new column is added
 * for that field. Moray uses the value in that column for (a) indexed searching
 * and (b) as the value for that field in gets. The problem is that the starter
 * value for that cell is *empty*, so we must backfill it from the JSON blob
 * in that row's "_value". This script does that.
 *
 * Examples:
 *      Backfill the 'name' field in the 'wf_jobs' bucket using a limit (really
 *      a batch size) of 10.
 *      $ ./backfill -i name -l 10 wf_jobs
 *
 *      Backfill the 'version' field in the 'ufds_o_smartdc' bucket, limiting
 *      the processing the rows with 'objectclass' equal to 'sdcpackage' or
 *      'sdcimage'.
 *      $ ./backfill -i version -l 50 -P objectclass=sdcpackage \
 *           -P objectclass=sdcimage ufds_o_smartdc
 */


var p = console.log;
var path = require('path');
var util = require('util'),
    format = util.format;
var bunyan = require('bunyan');
var getopt = require('posix-getopt');
var ProgressBar = require('progbar').ProgressBar;

var moray = require('../lib');



///--- Globals

var LOG = bunyan.createLogger({
    name: path.basename(process.argv[1]),
    level: (process.env.LOG_LEVEL || 'info'),
    stream: process.stderr,
    serializers: bunyan.stdSerializers
});

// Total number of objects to backfill
var TOTAL = 0;
// Number of objects we've already backfilled:
var PROCESSED = 0;
var START = Date.now();


///--- Functions

function usage(msg) {
    if (msg) {
        console.error(msg);
    }

    var str = 'usage: ' + path.basename(process.argv[1]);
    // "limit" here is really batch size.
    str += ' [-v] [-h host] [-p port] [-i index] [-l batch-size] [-P predicate] bucket';
    console.error(str);
    process.exit(1);
}

function parseOptions() {
    var option;
    var opts = {
            host: '127.0.0.1',
            port: 2020,
            indexes: [],
            limit: 100,
            predicates: {}
    };
    var parser = new getopt.BasicParser('vh:p:l:i:P:', process.argv);
    var tmp;

    while ((option = parser.getopt()) !== undefined && !option.error) {
        switch (option.option) {
        case 'h':
            opts.host = option.optarg;
            break;

        case 'p':
            opts.port = parseInt(option.optarg, 10);
            break;

        case 'i':
            tmp = option.optarg;
            opts.indexes.push(tmp);
            break;

        case 'l':
            opts.limit = parseInt(option.optarg, 10);
            break;

        case 'P':
            var equal = option.optarg.indexOf('=');
            if (equal === -1) {
                usage('error: "-P" arg is not of the form "field=value":'
                    + option.optarg);
            }
            var field = option.optarg.slice(0, equal);
            var value = option.optarg.slice(equal + 1);
            if (!opts.predicates[field]) {
                opts.predicates[field] = [];
            }
            opts.predicates[field].push(value);
            break;


        case 'v':
            // Allows us to set -vvv -> this little hackery
            // just ensures that we're never < TRACE
            LOG.level(Math.max(bunyan.TRACE, (LOG.level() - 10)));
            if (LOG.level() <= bunyan.DEBUG)
                    LOG = LOG.child({src: true});
            break;

        default:
            process.exit(1);
            break;
        }
    }

    if (parser.optind() >= process.argv.length) {
        usage('missing required argument: "bucket"');
    }

    opts.name = process.argv[parser.optind()];
    return (opts);
}


var options = parseOptions();


function backfillBucket() {
    var client = moray.createClient({
        host: options.host,
        log: LOG,
        port: options.port
    });
    var cfg = options.config || {
        options: options.options
    };
    var bar;

    client.on('connect', function onConnect() {
        var pred;
        function getPredicate(cb) {
            client.getBucket(options.name, function (err, bucket) {
                if (err) return cb(err);
                var ary = [];
                options.indexes.forEach(function (i) {
                    ary.push('\'%' + i + '%\'');
                });
                pred = 'from ' + options.name + ' where _value like any (array[' +
                    ary.join(',') + '])';
                Object.keys(options.predicates).forEach(function (field) {
                    var isArray = bucket.index[field] && bucket.index[field].type[0] == '[';
                    var values = options.predicates[field];
                    if (isArray) {
                        pred += format(' and %s in (array[\'%s\'])', field, values.join("'], array['"));
                    } else {
                        pred += format(' and %s in (\'%s\')', field, values.join("', '"));
                    }
                });
                cb(null, pred);
            });
        }

        function countObjects(cb) {
            if (TOTAL === 0) {
                var sql = 'select count(_id) ' + pred;
                // console.log(sql);

                var countReq = client.sql(sql);

                countReq.once('error', function (err) {
                        console.error(err.message);
                        return cb(err);
                });

                countReq.on('record', function (obj) {
                    if (typeof (obj) === 'object' && obj !== null) {
                        TOTAL = Number(obj.count);
                        console.log('Backfilling %d records', TOTAL);
                        bar = new ProgressBar({
                            size: TOTAL,
                            filename: options.name
                        });
                    }
                });

                countReq.once('end', function () {
                    return cb();
                });
            } else {
                return cb();
            }
        }

        function backfillObjects(offset, limit, cb) {
            var done = 0;
            var _2update = {};

            function wait() {
                if (done === limit || TOTAL === PROCESSED) {
                    return cb();
                } else {
                    return setTimeout(wait, 1000);
                }
            }

            var sql = 'select * ' + pred + ' order by _id limit ' + limit +
                    ' offset ' + offset;

            var req = client.sql(sql);

            req.once('error', function (err) {
                    console.error(err.message);
                    return cb(err);
            });

            req.on('record', function (obj) {
                if (obj) {
                    _2update[obj._key] = obj;
                }
            });

            req.on('end', function () {
                Object.keys(_2update).forEach(function (key) {
                    var data = JSON.parse(_2update[key]._value);
                    var skip = true;
                    for (var i = 0; i < options.indexes.length; i++) {
                        // XXX Not sure about a UFDS field with multiple values.
                        var idx = options.indexes[i];
                        if (data.hasOwnProperty(idx)
                            && String(data[idx]) !== _2update[key][idx]) {
                            skip = false;
                            break;
                        }
                    }
                    bar.advance(1);
                    if (skip) {
                        done += 1;
                        PROCESSED += 1;
                        return;
                    }
                    client.putObject(options.name, key, data, function (err) {
                        done += 1;
                        PROCESSED += 1;
                        if (err) {
                            bar._write('error with _key "' + key + '":'
                                + err.message, true);
                        } else {
                            // Note: hack into progbar's internal write so
                            // we can erase the current progbar. This *sort*
                            // of works. It is helpful for large sets with
                            // few changes at least so good enough.
                            bar._write('Updated ' + options.name
                                + ' record with _key "' + key + '"\n', true);
                        }
                    });
                });
                return wait();
            });

        }

        function processCb(err) {
            if (err) {
                console.log(err.message);
                if (err.message ===
                        'the underlying connection has been closed') {
                    LOG.warn('Waiting for client to reconnect');
                    client.once('connect', function reconnectCallback() {
                        backfillObjects(PROCESSED, options.limit, processCb);
                    });
                }
                return (false);
            } else if (PROCESSED < TOTAL) {
                return backfillObjects(PROCESSED, options.limit, processCb);
            } else {
                bar.end();
                console.log('Backfill of %d objects done (in %d seconds)',
                    TOTAL, (Date.now() - START) / 1000);
                process.exit(0);
            }
        }

        getPredicate(function (pErr, pred_) {
            countObjects(function (err) {
                if (err) {
                    console.error(err.message);
                }
                backfillObjects(0, options.limit, processCb);
            });
        });
    });

}

backfillBucket();
