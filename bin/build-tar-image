#!/bin/bash
#
# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.
#

#
# Copyright 2019 Joyent, Inc.
# Copyright 2022 MNX Cloud, Inc.
#

if [[ -n "$TRACE" ]]; then
    # BASHSTYLED
    export PS4='[\D{%FT%TZ}] ${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
    set -o xtrace
fi

ROOT=$(cd $(dirname $0)/../; pwd)

. "${ROOT}/buildtools/lib/error_handler.sh"
. "${ROOT}/buildtools/lib/common.sh"

function usage {
    if [[ -n "$1" ]]; then
        echo "ERROR: $1" >&2
    fi
    echo "" >&2
    echo "Usage:" >&2
    echo "    $0" >&2
    echo "" >&2
    exit 1
}

while getopts 'cr' name; do
    case "${name}" in
    c|r)
        usage "the \"-${name}\" option is no longer supported"
        ;;
    \?)
        usage 'unknown option'
        ;;
    esac
done
shift $((OPTIND - 1))

# Write output to log file.
THIS_TIMESTAMP=${TIMESTAMP}
if [[ -z "$THIS_TIMESTAMP" ]]; then
    THIS_TIMESTAMP=$(date -u "+%Y%m%dT%H%M%SZ")
fi
LOGDIR="${ROOT}/log"
LOGFILE="${LOGDIR}/build.log.${THIS_TIMESTAMP}"
RONNJS="${ROOT}/buildtools/ronnjs/bin/ronn.js"

mkdir -p log
exec > >(tee ${LOGFILE}) 2>&1

. "${ROOT}/buildtools/lib/trace_logger.sh"

# Tools.
if which gawk 2>/dev/null; then
    AWK=gawk
else
    AWK=awk
fi
GREP=grep
if [[ $(uname -s) == 'SunOS' ]]; then
    SUM='/usr/bin/sum -x sha1'
else
    SUM='shasum'
fi
JSON="${ROOT}/bin/json"
JSONMERGE="${ROOT}/bin/json-merge"
BUILDSPEC="${ROOT}/bin/buildspec"

# Make sure we use the path to the manta tools we built with 'make deps'
export PATH="${ROOT}/node_modules/manta/bin:${PATH}"

# BASHSTYLED
# See https://github.com/joyent/triton/blob/master/docs/developer-guide/release-engineering.md#package-versioning
# for package versioning details.
THIS_BRANCH=$(git symbolic-ref HEAD | cut -d'/' -f3)
THIS_GITDESCRIBE=g$(git describe --all --long | $AWK -F'-g' '{print $NF}')
THIS_BUILDSTAMP=${THIS_BRANCH}-${THIS_TIMESTAMP}-${THIS_GITDESCRIBE}

# "SDC_VERSION" is the version value that gets exposed to the public
# for development builds this will read <ts>.<branch>.<sha> of the build
# this value ends up in /usbkey/sdc_version
if [[ -z $SDC_VERSION ]]; then
    SDC_VERSION=${THIS_BUILDSTAMP}
fi

echo ">> Starting build at $(date)"

function check_nodejs
{
    if ! which node 2>/dev/null; then
        fatal "build-image requires \"node\" to be in your PATH"
    fi

    ver="$(node --version)"
    micro=${ver##*.}
    front=${ver%.*}
    minor=${front##*.}

    if [[ $(echo '{"foo": "bar"}' | ${JSON} foo) == 'bar' ]]; then
        echo "Your version of node.js is ok!"
    else
        fatal "You need to have a working node.js installed for this to work!"
    fi
}

CACHE="${ROOT}/cache"
STAGE="${CACHE}/stage"
ERROR=0
CLEANED=0

PLATFORM=$(uname -s)
if [[ ${PLATFORM} == 'Darwin' || ${PLATFORM} == 'SunOS' || \
      ${PLATFORM} == 'Linux' ]]; then
    source ${ROOT}/bin/include-tar-generic
    version
else
    echo "FATAL: Unsupported platform '${PLATFORM}'"
fi

function test_rootperms
{
    # root access is only required on SunOS
    [[ ${PLATFORM} != 'SunOS' ]] && return
    su_uid=$(${SUCMD} id -u)
    if [[ ${su_uid} -ne 0 ]]; then
        fatal "Can't get root priviledges."
    fi
}

function load_buildspec
{
    BUILD_TGZ=$(build_spec build-tgz)
}

function create_directories
{
    if [ ! -d "${ROOT}/cache" ]; then
        echo "==> Creating cache/"
        mkdir -p ${ROOT}/cache
    fi

    if [ ! -d "${ROOT}/mnt" ]; then
        echo "==> Creating mnt/"
        mkdir -p ${ROOT}/mnt
    fi

    echo "==> Creating stage/"
    rm -rf ${STAGE}
    mkdir -p ${STAGE}
}

#
# The console configuration is a little bit complicated below.  Since some
# system's redirection uses ttya, and some ttyb, we'll configure loader to
# attempt to use all possible ttys.
#
# But we also need to pass through "os_console" for the kernel, so we can see
# kernel output on the console requested.
#
function generate_loader_config
{
    local serial_dev
    local console
    local ipxe

    echo "==> Generating boot loader configuration "

    serial_dev=$(build_spec serial-dev)
    os_console=$(build_spec console)
    smt_enabled=$(build_spec smt_enabled)
    ipxe=$(build_spec ipxe)

    [[ -z "${ipxe}" ]] && ipxe="true"
    [[ -z "${serial_dev}" ]] && serial_dev="ttyb"
    [[ -z "${os_console}" ]] && os_console="${serial_dev}"
    [[ -z "${smt_enabled}" ]] && smt_enabled="true"

    case "${serial_dev}" in
    ttya) lconsole="ttya,ttyb,ttyc,ttyd" ;;
    ttyb) lconsole="ttyb,ttya,ttyc,ttyd" ;;
    ttyc) lconsole="ttyc,ttya,ttyb,ttyd" ;;
    ttyd) lconsole="ttyd,ttya,ttyb,ttyc" ;;
    *) fatal "Unknown serial-dev \"${serial_dev}\"" ;;
    esac

    case "${os_console}" in
    text|graphics|vga)
        os_console="text"
        lconsole="text,${lconsole}"
        ;;

    serial)
        os_console="${serial_dev}"
        lconsole="${lconsole},text"
        ;;

    ttya|ttyb|ttyc|ttyd)
        lconsole="${lconsole},text"
        ;;

    *)
        fatal "Unknown console device \"${os_console}\""
        ;;
    esac

    cp -f ${STAGE}/boot/loader.conf.tmpl ${STAGE}/boot/loader.conf

    echo "ipxe=\"${ipxe}\"" >>${STAGE}/boot/loader.conf
    echo "smt_enabled=\"${smt_enabled}\"" >>${STAGE}/boot/loader.conf
    echo "console=\"${lconsole}\"" >>${STAGE}/boot/loader.conf
    echo "os_console=\"${os_console}\"" >>${STAGE}/boot/loader.conf
}

function copy_base
{
    echo "==> Creating .joyliveusb file"
    touch ${STAGE}/.joyliveusb

    echo "==> Copying in scripts/"
    cp -r scripts ${STAGE}/scripts

    if [[ -d "65-files" ]]; then
        echo "==> Copying in 65-files/"
        mkdir -p ${STAGE}/65-files
        cp 65-files/* ${STAGE}/65-files/
    fi

    echo "==> Copying in default/"
    cp -r default ${STAGE}/default

    echo "==> Copying in usbkey/contents/"
    cp -r proto/opt/smartdc/share/usbkey/contents/* ${STAGE}

    echo "==> Copying in LICENSE"
    cp -r LICENSE ${STAGE}/LICENSE
}

function copy_config
{
    # Clear current configs from stage area
    rm -f ${STAGE}/config || true
    rm -rf ${STAGE}/config.inc || true

    cp -r config/config.inc ${STAGE}/config.inc

    if [[ -f config/banner ]]; then
        cp config/banner ${STAGE}/banner
    fi

    # Flag SAPI for headnode.sh.
    # TODO:matt Is this still needed?
    echo "USE_SAPI=\"true\"" >> ${STAGE}/config.inc/generic
}

function valid_archive
{
    filename=$1
    if [[ -f ${filename} ]] && ${TAR} -tf ${filename} > /dev/null; then
        return 0
    else
        return 1
    fi
}

function cleanup_logs
{
    local kept=0
    local keep_logs=
    keep_logs=$(build_spec keep-logs)

    if [[ -n ${keep_logs} && ${keep_logs} -gt 0 ]]; then
        for log in $(ls -1t ${LOGDIR}); do
            if [[ ${kept} -lt ${keep_logs} ]]; then
                echo "KEEPING: ${log}" >&2
                kept=$((${kept} + 1))
            else
                echo "DELETING: ${log}" >&2
                rm ${LOGDIR}/${log} >&2
            fi
        done
    fi
}

function get_bit
{
    local name
    local linkpath
    name=$1

    if [[ ! -f "${CACHE}/${name}" ]]; then
        fatal "build artefact \"${name}\" was not found in \"${CACHE}\""
    fi

    if ! linkpath="$(readlink -n "${CACHE}/${name}")"; then
        fatal "could not get target of artefact symlink \"${name}\""
    fi

    printf '%s/%s' "${CACHE}" "${linkpath}"
    return 0
}

function _check_vpn
{
    if [[ ${HAVE_INTERNET} == "true" ]]; then
        local host=${1##*//}
        ping -o -t 3 ${host} &> /dev/null
        local result=$?
        if [[ ${result} -ne 0 ]]; then
            echo "Can't ping ${host} (are you on the VPN?)"
            exit ${result}
        fi
    fi
}


# Get the platform to use. In order, attempt to use:
#
# - the local file path in the PLATFORM_FILE envvar
# - the symlink "file.platform.tgz" (or "file.platform-debug.tgz") as
#   prepared by the build artefact download system
#
function copy_platform
{
    local platform_image
    platform_image=$(build_spec platform-image)
    local platform_release
    platform_release=$(build_spec platform-release)

    local plat_suffix=""
    if [[ "$(${BUILDSPEC} -f debug-platform)" == "true" ]]; then
        plat_suffix="-debug"
        echo "Using DEBUG platform"
    fi

    local image
    if [[ -n "${PLATFORM_FILE}" ]]; then
        image=${PLATFORM_FILE}
        if ! valid_archive "${image}"; then
            fatal "Refusing to use corrupt platform ${image}"
        fi
    else
        image="$(get_bit "file.platform${plat_suffix}.tgz")"
    fi
    echo "==> Using ${image} as platform image"

    export USING_PLATFORM=${image}

    LIVEIMG_VERSION=`basename ${image} \
        | sed -e "s/platform.*-\([0-9TZ]*\)\.tgz/\1/"`

    echo "==> Unpacking `basename ${image}`"
    (set -e; cd ${STAGE}/; ${TAR} -zxf ${image}; \
        mkdir -p os/${LIVEIMG_VERSION}; \
        mv platform-* os/${LIVEIMG_VERSION}/platform) \
        || fatal "Unable to unpack platform"
    if [[ -f ${STAGE}/os/${LIVEIMG_VERSION}/platform/root.password ]]; then
        (cd ${STAGE}/ \
            && mkdir -p private \
            && mv -f os/${LIVEIMG_VERSION}/platform/root.password \
                private/root.password.${LIVEIMG_VERSION}) \
            || fatal "Unable to move root.password"
    fi
    root_pw=$(cat ${STAGE}/private/root.password.${LIVEIMG_VERSION})
    echo "Root password is: '${root_pw}'"

    #
    # By default, loader on illumos expects the "platform" directory to be at
    # to be a top-level directory in the root filesystem and sets the location
    # of the kernel to be relative to that.  On Triton, the platform directory
    # exists under /os/${LIVEIMG_VERSION}, so we override it by setting the
    # full paths to the kernel, boot archive and archive hash in loader.conf.
    #
    local defplatdir="/os/${LIVEIMG_VERSION}"
    echo "bootfile=\"$defplatdir/platform/i86pc/kernel/amd64/unix\"" \
        >> ${STAGE}/boot/loader.conf
    echo "boot_archive_name=\"$defplatdir/platform/i86pc/amd64/boot_archive\"" \
        >> ${STAGE}/boot/loader.conf
    # BASHSTYLED
    echo "boot_archive.hash_name=\"$defplatdir/platform/i86pc/amd64/boot_archive.hash\"" \
        >> ${STAGE}/boot/loader.conf

    echo "platform-version=\"${LIVEIMG_VERSION}\"" >> ${STAGE}/boot/loader.conf

    rm -f ${LOGDIR}/latest
    ln -s ${LOGFILE} ${LOGDIR}/latest

    loops=
}


# Copy the latest 'sdcadm' build into the usbkey stage dir.
#
# "sdcadm-release" in build.spec[.local] is either a branch build (default is
# "master") or a full path to a sdcadm shar to use.
#
function copy_sdcadm
{
    local path
    path=$(get_bit "file.sdcadm.sh")

    echo "Copying $(basename $path) to \$stage/sdcadm-install.sh"
    cp "${path}" "${STAGE}/sdcadm-install.sh"
}

function copy_agentsshar
{
    local path
    path=$(get_bit "file.agents.sh")

    echo "Copying $(basename $path) to stage."
    mkdir -p ${STAGE}/ur-scripts
    cp "${path}" "${STAGE}/ur-scripts/"
}

function copy_sapi_config
{
    local manifests=${ROOT}/config/sapi/manifests/
    local services=${ROOT}/config/sapi/services/
    local application=${ROOT}/config/sapi/application.json
    NO_RABBIT=$(build_spec no-rabbit)

    cp -r ${manifests} ${STAGE}/manifests
    cp -r ${services} ${STAGE}/services
    if [[ "$NO_RABBIT" == "true" ]]; then
        cat "${application}" | ${JSON} -e \
            "this.metadata.no_rabbit = true;" > ${STAGE}/application.json
    else
        cp ${application} ${STAGE}/application.json
    fi
}

function test_gzip
{
    if [[ -z ${NO_COMPRESS_CHECK} ]]; then
        printf '  ==> test gzip "%s"\n' "$(basename "${1}")"
        gzip -t "${1}" || fatal "gzip file ${1} is corrupt; aborting"
    fi
}

function test_bzip2
{
    if [[ -z ${NO_COMPRESS_CHECK} ]]; then
        printf '  ==> test bzip2 "%s"\n' "$(basename "${1}")"
        bzip2 -t "${1}" || fatal "bzip2 file ${1} is corrupt; aborting"
    fi
}

#
# Test the given compressed file.
# Usage:
#   test_compression FILE-PATH COMPRESSION-TYPE
# where COMPRESSION-TYPE is one of 'bzip2', 'gzip', or none per
# <https://images.smartos.org/docs/#manifest-files>.
#
function test_compression
{
    if [[ -z ${NO_COMPRESS_CHECK} ]]; then
        case "${2}" in
        gzip)
            printf '  ==> test gzip compression "%s"\n' "$(basename "${1}")"
            gzip -t "${1}" || fatal "gzip file ${1} is corrupt; aborting"
            ;;
        bzip2)
            printf '  ==> test bzip2 compression "%s"\n' "$(basename "${1}")"
            bzip2 -t "${1}" || fatal "bzip2 file ${1} is corrupt; aborting"
            ;;
        none)
            ;;
        *)
            fatal "invalid compression type: '$2'"
            ;;
        esac
    fi
}

function copy_core_zone_image
{
    local name=$1
    local file_manifest
    local file_image
    local service
    local image_uuid
    local origin_uuid
    local origin_manifest
    local origin_file

    mkdir -p "${STAGE}/images"

    #
    # Locate image manifest and compressed stream file:
    #
    file_manifest="$(get_bit "zone.${name}.imgmanifest")"
    file_image="$(get_bit "zone.${name}.imgfile")"
    test_gzip "${file_image}"
    image_uuid="$(${JSON} -f "${file_manifest}" uuid)"

    #
    # Copy files:
    #
    echo "  ==> copy 'images/${image_uuid}.imgmanifest'"
    ln "${file_manifest}" "${STAGE}/images/${image_uuid}.imgmanifest"
    echo "  ==> copy 'images/${image_uuid}.imgfile'"
    ln "${file_image}" "${STAGE}/images/${image_uuid}.imgfile"

    #
    # Copy image ancestry (origin images):
    #
    origin_uuid="$(${JSON} -f "${file_manifest}" origin)"
    while true; do
        if [[ -z "${origin_uuid}" ]]; then
            break
        fi
        if [[ -f "${STAGE}/images/${origin_uuid}.imgmanifest" ]]; then
            # Already have it in "images/".
            break
        fi

        origin_manifest="$(get_bit "image.${origin_uuid}.imgmanifest")"
        origin_file="$(get_bit "image.${origin_uuid}.imgfile")"
        test_compression "${origin_file}" \
            "$(${JSON} -f "${origin_manifest}" files.0.compression)"

        echo "  ==> copy origin 'images/${origin_uuid}.imgmanifest'"
        ln "${origin_manifest}" "${STAGE}/images/${origin_uuid}.imgmanifest"
        echo "  ==> copy origin 'images/${origin_uuid}.imgfile'"
        ln "${origin_file}" "${STAGE}/images/${origin_uuid}.imgfile"

        origin_uuid="$(${JSON} -f "${origin_manifest}" origin)"
    done

    #
    # Write metadata:
    #
    # The initial bootstrap of SAPI during headnode setup uses JSON objects
    # stored in files of the form:
    #
    #   config/services/${service_name}/service.json"
    #
    # Write the image uuid we are shipping for this zone into that file as
    # a parameter; the template files contain an IMAGE_UUID placeholder
    # for this purpose.
    #
    service="${STAGE}/services/${name}/service.json"
    if [[ -f ${service} ]]; then
        sed -i'.tmp' -e "s|IMAGE_UUID|${image_uuid}|" "${service}"
        rm -f "${service}.tmp"
    fi

    #
    # The image uuid is written to this file so that headnode
    # setup may locate it.  The USB key filesystem is mounted for
    # setup using pcfs(7FS) with the "foldcase" option, so beware that the
    # filename must be lowercase. (See also: mount_pcfs(1M)).
    #
    echo "${image_uuid}" > "${STAGE}/zones/${name}/image"
}

function copy_zones
{
    local zone
    local zone_list
    local f

    zone_list="$(${BUILDSPEC} -a zones)"

    mkdir -p "${STAGE}/zones"

    for zone in ${zone_list}; do
        echo "==> Copying zone '${zone}'"

        #
        # We use the "-L" flag to copy to ensure that the _target_
        # of any symlinks is copied as a file, not a symlink.
        #
        if [[ -d "${ROOT}/zones/${zone}" ]]; then
            cp -R -L "${ROOT}/zones/${zone}" "${STAGE}/zones/"
        else
            mkdir -p "${STAGE}/zones/${zone}"
        fi

        copy_core_zone_image "${zone}"
    done
}

function copy_tools
{
    if [[ ! -f ${ROOT}/tools.tar.gz ]]; then
        fatal "could not find tools.tar.gz; did 'make tools.tar.gz' run?"
    fi
    if [[ ! -f ${ROOT}/cn_tools.tar.gz ]]; then
        fatal "could not find cn_tools.tar.gz; did " \
            "'make cn_tools.tar.gz' run?"
    fi
    cp ${ROOT}/tools.tar.gz ${STAGE}/tools.tar.gz
    cp ${ROOT}/cn_tools.tar.gz ${STAGE}/cn_tools.tar.gz
}

function copy_to_mount
{
    echo "${THIS_BUILDSTAMP}" > ${STAGE}/version

    (cd ${STAGE} && ${TAR} ${TAR_ROOT} -cf - * .[a-zA-Z]*) \
        | (cd ${MNT_DIR} && ${SUCMD} ${TAR} --no-same-owner -xvf -) \
        || fatal "Unable to copy files to mount"
}

function add_manifests
{
    # build manifest of USB files + move in boot_archive manifest
    rm -f $STAGE/usb_key.manifest || true
    (cd ${STAGE}/ \
        && find . -type f -exec openssl dgst -md5 {} \; | awk '{print $NF}') \
        > $STAGE/usb_key.manifest
    [[ $? -eq 0 ]] || fatal "Unable to add manifests"
    rm -f $STAGE/boot_archive.manifest || true

    # BASHSTYLED
    cp ${STAGE}/os/${LIVEIMG_VERSION}/platform/i86pc/amd64/boot_archive.manifest \
        $STAGE/boot_archive.manifest
    chmod 444 $STAGE/*.manifest
}

# Main()

check_nodejs
test_rootperms

create_directories
load_buildspec
copy_base
generate_loader_config
copy_platform
copy_sdcadm
copy_agentsshar
copy_sapi_config
copy_zones
copy_tools
copy_config

unpack_image
add_manifests
mount_image
trap 'cleanup' EXIT
copy_to_mount
cleanup
create_output
cleanup_logs

# Unfortunately the log contains a whole bunch of progress updates,
# clean that up.
if [[ -f ${LOGFILE} ]]; then
    cat ${LOGFILE} | ${GREP} -v "
" > ${LOGFILE}.tmp \
    && mv ${LOGFILE}.tmp ${LOGFILE}
fi

if [ ${ERROR} -ne 0 ]; then
    fatal "==> SOMETHING WENT WRONG! ERROR: ${ERROR}"
fi

echo "==> DONE"

exit 0
