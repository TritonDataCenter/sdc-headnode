#!/bin/bash
#
# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.
#

#
# Copyright (c) 2014, Joyent, Inc.
#

#
# We set errexit (a.k.a. "set -e") to force an exit on error conditions, but
# there are many important error conditions that this does not capture --
# first among them failures within a pipeline (only the exit status of the
# final stage is propagated).  To exit on these failures, we also set
# "pipefail" (a very useful option introduced to bash as of version 3 that
# propagates any non-zero exit values in a pipeline).
#

set -o errexit
set -o pipefail

shopt -s extglob

ROOT=$(cd $(dirname $0)/../; pwd)

# Write output to log file.
THIS_TIMESTAMP=${TIMESTAMP}
if [[ -z "$THIS_TIMESTAMP" ]]; then
    THIS_TIMESTAMP=$(date -u "+%Y%m%dT%H%M%SZ")
fi
LOGDIR="${ROOT}/log"
LOGFILE="${LOGDIR}/build.log.${THIS_TIMESTAMP}"
RONNJS="${ROOT}/bin/ronnjs/bin/ronn.js"

mkdir -p log
exec > >(tee ${LOGFILE}) 2>&1

if [[ $(echo $BASH_VERSION | cut -d '.' -f1-2) > 4.0 ]]; then
    BASH_IS_NOT_ANCIENT='true'
fi
#export PS4='${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
#set -x
if [[ `hostname` == "bh1-autobuild" || `hostname` == "bldzone2.joyent.us" \
      || ! -z $BASH_IS_NOT_ANCIENT ]]; then
    # BASHSTYLED
    export PS4='[\D{%FT%TZ}] ${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
    export BASH_XTRACEFD=4
    set -o xtrace
elif [[ -n ${TRACE} ]]; then
    set -o xtrace
fi


# Tools.
AWK=$((which gawk 2>/dev/null | grep -v "^no ") || which awk)
TAR=tar
GREP=grep
if [[ `uname -s` == 'SunOS' ]]; then
  SUM='/usr/bin/sum -x sha1'
else
  SUM='shasum'
fi

# Make sure we use the path to the manta tools we built with 'make deps'
export PATH="${ROOT}/node_modules/manta/bin:${PATH}"

# See MGs Package Versioning for details
# (https://mo.joyent.com/mountain-gorilla/blob/master/README.md#L74).
THIS_BRANCH=$(git symbolic-ref HEAD | cut -d'/' -f3)
THIS_GITDESCRIBE=g$(git describe --all --long | $AWK -F'-g' '{print $NF}')
THIS_BUILDSTAMP=${THIS_BRANCH}-${THIS_TIMESTAMP}-${THIS_GITDESCRIBE}

# "SDC_VERSION" is the version value that gets exposed to the public
# for development builds this will read <ts>.<branch>.<sha> of the build
# this value ends up in /usbkey/sdc_version
if [[ -z $SDC_VERSION ]]; then
  SDC_VERSION=${THIS_BUILDSTAMP}
fi

echo ">> Starting build at $(date)"

function fatal
{
    echo "$(basename $0): fatal error: $*" >&2
    exit 1
}

function errexit
{
    [[ $1 -ne 0 ]] || exit 0
    fatal "error exit status $1 at line $2"
}

function check_nodejs
{
    [[ ! `which node` ]] && fatal "build-image requires node to be in your path"

    ver=`node --version`
    micro=${ver##*.}
    front=${ver%.*}
    minor=${front##*.}

    # [[ $minor -ne 4 ]] && fatal "Node minor version must be 4"
    # [[ $micro -lt 9 ]] && fatal "Node micro version must be at least 9"

    if [[ $(echo '{"foo": "bar"}' | ${ROOT}/bin/json foo) == 'bar' ]]; then
        echo "Your version of node.js is ok!"
    else
        fatal "You need to have a working node.js installed for this to work!"
    fi
}

MERGED_SPEC=
if [[ -f "${ROOT}/build.spec" && -f "${ROOT}/build.spec.local" ]]; then
    MERGED_SPEC=$(${ROOT}/bin/json-merge \
                  ${ROOT}/build.spec ${ROOT}/build.spec.local);
elif [[ -f "${ROOT}/build.spec" ]]; then
    MERGED_SPEC=$(cat ${ROOT}/build.spec);
elif [[ -f "${ROOT}/build.spec.local" ]]; then
    MERGED_SPEC=$(cat ${ROOT}/build.spec.local);
fi

function build_spec () {
    local thing=$1;
    echo $(echo $MERGED_SPEC | ${ROOT}/bin/json ${thing});
};

trap 'errexit $? $LINENO' EXIT

STAGE="${ROOT}/cache/stage"
ERROR=0
CLEANED=0

CURL_OPTS=$(build_spec curl-opts)
SPEED_LIMIT=$(build_spec speed-limit)
NO_INTERNET=$(build_spec no-internet)

# Support for a regex pattern matched against bits to download from Manta for
# the build. If the bit's pattern matches this regex, then "no-internet":true
# is *ignored* for that bit. This is a way to do a usb-headnode build that
# only gets the latest of a subset of the bits, e.g.:
#       "no-internet": true
#       "no-internet-exceptions": "(cnapi|imgapi)"
NO_INTERNET_EXCEPTIONS=$(build_spec no-internet-exceptions)
[[ -n "$NO_INTERNET_EXCEPTIONS" ]] || NO_INTERNET_EXCEPTIONS='^$'


# --- Manta config
if [[ -n "$(build_spec manta-key-id)" ]]; then
    export MANTA_KEY_ID=$(build_spec manta-key-id)
elif [[ -z "$MANTA_KEY_ID" ]]; then
    export MANTA_KEY_ID=`ssh-keygen -l -f ~/.ssh/id_rsa.pub \
                         | awk '{print $2}' | tr -d '\n'`
fi
if [[ -z "$(build_spec manta-url)" ]]; then
    export MANTA_URL=https://us-east.manta.joyent.com
else
    export MANTA_URL="$(build_spec manta-url)"
fi

if [[ -z "$(build_spec manta-user)" ]]; then
    export MANTA_USER="Joyent_Dev"
else
    export MANTA_USER="$(build_spec manta-user)"
fi

# A quick attempt to get `mget` usage to *not* require MANTA_KEY_ID
# for retrieve bits from a public area of Manta.
if [[ "$(build_spec joyent-build)" != "true"
        && -n "$(build_spec manta-base-path | (grep '^/\w\+/public/' || true))" ]]; then
    export MANTA_NO_AUTH=true
fi

if [[ "$(build_spec builds-proxy)" == "true" ]]; then
    BUILDS_PROXY_URL=$(build_spec builds-proxy-url)
    [[ -n "$BUILDS_PROXY_URL" ]] \
        || fatal "no 'builds-proxy-url' in build.spec.local"
    BUILDS_PROXY_AUTH_FILE=$(build_spec builds-proxy-auth-file)
    [[ -n "$BUILDS_PROXY_AUTH_FILE" ]] \
        || fatal "no 'builds-proxy-auth-file' in build.spec.local"
    BUILDS_PROXY_AUTH_FILE=$(echo $BUILDS_PROXY_AUTH_FILE \
                             | sed -e "s|^~/|$HOME/|")
    BUILDS_PROXY_USER=$(json -f $BUILDS_PROXY_AUTH_FILE username)
    [[ -n "$BUILDS_PROXY_USER" ]] \
        || fatal "no 'username' field in '$BUILDS_PROXY_AUTH_FILE'"
    BUILDS_PROXY_PASSWD=$(json -f $BUILDS_PROXY_AUTH_FILE password)
    [[ -n "$BUILDS_PROXY_PASSWD" ]] \
        || fatal "no 'password' field in '$BUILDS_PROXY_AUTH_FILE'"
fi

if [[ -n ${SPEED_LIMIT} ]]; then
    CURL_OPTS="${CURL_OPTS} --limit-rate ${SPEED_LIMIT}"
fi

# Get BITS_BRANCH if necessary.
if [[ -z "$BITS_BRANCH" ]]; then
    BITS_BRANCH=$(build_spec bits-branch)
fi

[[ -z "$BITS_BRANCH" ]] && fatal "Could not determine a BITS_BRANCH."
echo "BITS_BRANCH: $BITS_BRANCH"

if [[ $1 == "-r" ]]; then
    # XXX - Temporary warning about recipes
    # BASHSTYLED
    echo "WARNING: Recipes are no longer supported... sleeping for while so you notice"
    sleep 30
    shift
    shift
fi

if [[ $1 == "-c" ]]; then
    shift
    # BASHSTYLED
    echo "NOTICE: building without config is the only option now, -c is unnecessary."
fi

PLATFORM=$(uname -s)
if [[ ${PLATFORM} == 'Darwin' || ${PLATFORM} == 'SunOS' ]]; then
    source ${ROOT}/bin/include-tar-generic
    version
else
    echo "FATAL: Unsupported platform '${PLATFORM}'"
fi

echo -n "==> Checking for Internets... "
if [[ ${NO_INTERNET} == "true" ]] || ! can_has_internets; then
    echo "No Internets! Activating countermeasures!"
    HAVE_INTERNET="false"
else
    echo "Yep!"
    HAVE_INTERNET="true"
fi

function test_rootperms
{
    # root access is no longer required on OSX
    [[ ${PLATFORM} == 'Darwin' ]] && return
    su_uid=$(${SUCMD} id -u)
    if [[ ${su_uid} -ne 0 ]]; then
        fatal "Can't get root priviledges."
    fi
}

function load_buildspec
{
    PLATFORM_RELEASE=$(build_spec platform-release)
    BUILD_TGZ=$(build_spec build-tgz)

    [[ -n ${PLATFORM_RELEASE} ]] && echo "platform-release: ${PLATFORM_RELEASE}"
}

function create_directories
{
    if [ ! -d "${ROOT}/cache" ]; then
        echo "==> Creating cache/"
        mkdir -p ${ROOT}/cache
    fi

    if [ ! -d "${ROOT}/mnt" ]; then
        echo "==> Creating mnt/"
        mkdir -p ${ROOT}/mnt
    fi

    echo "==> Creating stage/"
    rm -rf ${STAGE}
    mkdir -p ${STAGE}
}

function generate_grub_menu
{
    local unit=
    local serial_dev
    serial_dev=$(build_spec serial-dev)
    local console
    console=$(build_spec console)
    local default_boot_option
    default_boot_option=$(build_spec default-boot-option)

    # Feature flag for HEAD-2093
    local enable_dr
    enable_dr=$(build_spec enable-disaster-recovery)
    local DR_VAL='#DR '
    [[ ${enable_dr} == "true" ]] && DR_VAL=''

    echo "==> Generating grub menu"

    [[ -z "${serial_dev}" ]] && serial_dev=ttyb
    [[ -z "${console}" ]] && console="serial"
    [[ -z "${default_boot_option}" ]] && default_boot_option=0

    #
    # This section describes the serial-dev and console parameters.  These
    # values may be overridden in build.spec{,.local}.
    #
    # serial-dev is the serial console device on the target system.  It
    # defaults to ttyb (illumos) aka COM2 (FreeDOS), which is legacy I/O
    # port 2f8 interrupt 3.
    #
    # console is used to set the default value of the GRUB variable
    # "os_console", which selects the post-boot console device.  It may
    # be one of "serial", in which case the serial device specified by
    # serial-dev is used, or "text" in which case an attached keyboard
    # and VGA device is used.  For backward compatibility, "graphics"
    # and "vga" are aliases for "text".  In addition, an explicit serial
    # device may be specified, in which case its value will override
    # serial-dev.  This is almost certainly not what you want, since it
    # will mean that post-boot I/O will be to/from a different device
    # than was used during boot.  Note that the operator can change the
    # post-boot console by modifying the os_console GRUB variable before
    # booting.
    #
    # When the system boots, GRUB will display its output to the VGA
    # device, if one is present, and the device specified by serial-dev,
    # if it exists.  It will also accept input from either an attached
    # keyboard or serial-dev.  Once a boot selection is made, the value
    # of the os_console GRUB variable is passed to the operating system
    # and used as the system console, unless a network boot is
    # performed.  In that case, the parameters received from the HN will
    # override all console selection made here or in the GRUB
    # environment; this may be modified for each CN using CNAPI.
    #
    # By default, serial-dev is "ttyb" and console is "serial".
    #
    case "${serial_dev}" in
    ttya)
        unit=0
        ;;
    ttyb)
        unit=1
        ;;
    ttyc)
        unit=2
        ;;
    ttyd)
        unit=3
        ;;
    *)
        fatal "Unknown serial device: ${serial_dev}"
        ;;
    esac

    case "${console}" in
    serial)
        console=${serial_dev}
        ;;
    ttya|ttyb|ttyc|ttyd)
        ;;
    text|graphics|vga)
        console=text
        ;;
    *)
        fatal "Unknown default console device: ${console}"
        ;;
    esac

    serial_string="--speed=115200 --unit=${unit} --word=8 --parity=no --stop=1"

    sed \
        -e "s/^#SERIAL/serial ${serial_string}/" \
        -e "s/DEFAULT_CONSOLE/${console}/g" \
        -e "s/^default.*$/default ${default_boot_option}/" \
        -e "s/^#DR /${DR_VAL}/" \
        boot/grub/menu.lst.tmpl \
        > ${STAGE}/boot/grub/menu.lst.tmpl
}

function copy_base
{
    local sbbranch
    sbbranch=$(build_spec sdcboot-release)
    local platbranch
    platbranch=$(build_spec platform-release)

    local plat_suf
    if [[ "$(build_spec debug-platform)" == "true" || -n "$DEBUG_BUILD" ]]; then
        plat_suf="-debug"
    else
        plat_suf=""
    fi

    local is_joyent
    is_joyent="$(build_spec joyent-build)"

    [[ -z ${sbbranch} ]] && sbbranch="master"
    [[ -z ${platbranch} ]] && platbranch="master"

    if [[ "${is_joyent}" == "true" ]]; then
        local ftbranch
        ftbranch=$(build_spec firmware-tools-release)
        [[ -z ${ftbranch} ]] && ftbranch="master"
    fi

    local sdcboot_path
    sdcboot_path=$(get_manta_bit \
        sdcboot/${sbbranch}/sdcboot-${sbbranch}-.*\.tgz)
    local platboot_path
    platboot_path=$(get_manta_bit \
        platform$plat_suf/${platbranch}/boot$plat_suf-${platbranch}-.*\.tgz)

    if [[ "${is_joyent}" == "true" ]]; then
        local firmware_path
        firmware_path=$(get_manta_bit \
            firmware-tools/${ftbranch}/firmware-tools-${ftbranch}-.*\.tgz \
            "joyent-manta-base-path")
    fi

    echo "==> Creating .joyliveusb file"
    touch ${STAGE}/.joyliveusb

    echo "==> Copying in scripts/"
    cp -r scripts ${STAGE}/scripts

    if [[ -d "65-files" ]]; then
        echo "==> Copying in 65-files/"
        mkdir -p ${STAGE}/65-files
        cp 65-files/* ${STAGE}/65-files/
    fi

    echo "==> Copying in zones/"
    cp -r zones ${STAGE}/zones

    echo "==> Copying in default/"
    cp -r default ${STAGE}/default

    echo "==> Copying in LICENSE"
    cp -r LICENSE ${STAGE}/LICENSE

    echo "==> Extracting platform boot bundle"
    (cd ${STAGE} && ${TAR} xzf ${platboot_path})
    [[ $? == 0 ]] || fatal "Failed to extract boot bundle"

    echo "==> Extracting sdcboot bundle"
    (cd ${STAGE} && ${TAR} xzf ${sdcboot_path})
    [[ $? == 0 ]] || fatal "Failed to extract sdcboot bundle"

    if [[ "${is_joyent}" == "true" ]]; then
        echo "==> Extracting firmware bundle"
        (cd ${STAGE} && ${TAR} xzf ${firmware_path})
        [[ $? == 0 ]] || fatal "Failed to extract firmware bundle"
    fi
}

function copy_config {

    # Clear current configs from stage area
    rm -f ${STAGE}/config || true
    rm -rf ${STAGE}/config.inc || true

    cp -r config/config.inc ${STAGE}/config.inc

    if [[ -f config/banner ]]; then
        cp config/banner ${STAGE}/banner
    fi

    # Flag SAPI for headnode.sh.
    # TODO:matt Is this still needed?
    echo "USE_SAPI=\"true\"" >> ${STAGE}/config.inc/generic
}

function valid_archive
{
    filename=$1
    if [[ -f ${filename} ]] && ${TAR} -tf ${filename} > /dev/null; then
        return 0
    else
        return 1
    fi
}

function cleanup_logs
{
    local kept=0
    local keep_logs=
    keep_logs=$(build_spec keep-logs)

    if [[ -n ${keep_logs} && ${keep_logs} -gt 0 ]]; then
        for log in $(ls -1t ${LOGDIR}); do
            if [[ ${kept} -lt ${keep_logs} ]]; then
                echo "KEEPING: ${log}" >&2
                kept=$((${kept} + 1))
            else
                echo "DELETING: ${log}" >&2
                rm ${LOGDIR}/${log} >&2
            fi
        done
    fi
}

function cleanup_bit
{
    local bits_pattern="^$1"

    local bits_dir="${ROOT}/cache"
    local kept=0
    local keep_bits=
    keep_bits=$(build_spec keep-bits)

    if [[ -n ${keep_bits} && ${keep_bits} -gt 0 ]]; then
        [[ -n ${TRACE} ]] \
            && echo "CLEANUP_BIT CALLED FOR: '${bits_pattern}'" >&2

        local bit=
        for bit in $(ls -1t ${bits_dir} | grep "${bits_pattern}"); do
            if [[ ! -f ${bits_dir}/${bit} ]]; then
                # skip non-file
                continue;
            fi
            if [[ ${kept} -lt ${keep_bits} ]]; then
                [[ -n ${TRACE} ]] && echo "KEEPING: ${bit}" >&2
                kept=$((${kept} + 1))
            else
                echo "DELETING: ${bit}" >&2
                rm ${bits_dir}/${bit} >&2
            fi
        done
    fi
}

# Get a bit from Manta to the local cache/ dir.
function get_manta_bit
{
    pattern=$1
    alternate_base_path_var=$2
    local get_bit_rv=

    local pattern_dir
    pattern_dir=$(dirname $pattern)
    local file_name
    file_name=$(basename $pattern)
    local joyent_bits_base_path
    joyent_bits_base_path=$(build_spec joyent-manta-base-path)

    local base_path=
    if [[ -n ${alternate_base_path_var} ]]; then
        base_path=$(build_spec ${alternate_base_path_var})
    else
        base_path=$(build_spec manta-base-path)
    fi

    local branch=${BITS_BRANCH}
    local have_branch_override
    have_branch_override=$(dirname $pattern_dir)
    if [[ "$have_branch_override" != "." ]]; then
        branch=$(basename $pattern_dir)
        pattern_dir=$(dirname $pattern_dir)
    fi

    if [[ -n "${BITS_DIR}" ]]; then
        # Local BITS_DIR example:
        #   /home/jill/joy/mountain-gorilla/bits
        # where pattern='agentsshar/agents-master-*' is at:
        #   /home/jill/joy/mountain-gorilla/bits/agentsshar/agents-master-*

        local pattern_base
        pattern_base="^$(basename $pattern)"
        local latest_name
        latest_name=$(ls -1 ${BITS_DIR}/${pattern_dir}/ \
           | grep "${pattern_base}" \
           | sort \
           | tail -1)
        [[ -n "${latest_name}" ]] \
            || fatal "'${BITS_DIR}/${pattern}' did not match any files."

        local latest_path=${BITS_DIR}/${pattern_dir}/${latest_name}
        local latest_filename
        latest_filename=$(basename $latest_path)
        local cache_path=${ROOT}/cache/${latest_filename}
        if [[ ! -f $cache_path ]]; then
            echo "Copying '${latest_path}' bit to cache." >&2
            cp ${latest_path} ${cache_path}
        fi
        get_bit_rv=${cache_path}
        cleanup_bit "${file_name}"

        echo "${get_bit_rv}"
        return;
    fi

    if [[ ${HAVE_INTERNET} == "false" \
            && -z "$(echo "$pattern" | \
                     egrep "${NO_INTERNET_EXCEPTIONS}")"  ]]; then
        local pattern_base
        pattern_base="^$(basename $pattern)"
        local latest_path
        latest_path=$(ls -1 ${ROOT}/cache/ \
           | grep "${pattern_base}" \
           | sort \
           | tail -1)
        # BEGIN BASHSTYLED
        [[ -n "${latest_path}" ]] \
            || fatal "Don't have any '${pattern_base}' in '${ROOT}/cache' and no internet."
        # END BASHSTYLED
        echo "${ROOT}/cache/${latest_path}"
        return
    fi

    if [[ -n "$BUILDS_PROXY_URL" ]]; then
        # BASHSTYLED
        BUILDS_CURL="curl ${CURL_OPTS} -kSf -u $BUILDS_PROXY_USER:$BUILDS_PROXY_PASSWD"
        # BASHSTYLED
        local latest_file="$BUILDS_PROXY_URL/${base_path}/${pattern_dir}/${branch}-latest"
        local latest_mdir
        latest_mdir=$($BUILDS_CURL -s --url ${latest_file})

        # Fallback to joyent_bits_base_path in case this is a private build
        if [[ -z ${latest_mdir} && -n ${joyent_bits_base_path}
            && ${joyent_bits_base_path} != ${base_path} ]]; then

            base_path=${joyent_bits_base_path}
            # BASHSTYLED
            latest_file="$BUILDS_PROXY_URL/${base_path}/${pattern_dir}/${branch}-latest"
            latest_mdir=$($BUILDS_CURL -s --url ${latest_file})
        fi

        local latest_dir
        # BASHSTYLED
        latest_dir=$BUILDS_PROXY_URL/${base_path}/$pattern_dir/$(basename $latest_mdir)
        # BASHSTYLED
        local latest_filename
        latest_filename=$($BUILDS_CURL -s --url $latest_dir/$pattern_dir/ \
            | grep "$file_name" | head -1 \
            | cut -d'"' -f2 | cut -d'"' -f1)
        local latest_path=$latest_dir/$pattern_dir/$latest_filename
        local cache_path=${ROOT}/cache/${latest_filename}

        local md5
        md5=$($BUILDS_CURL $latest_dir/md5sums.txt 2>/dev/null \
                    | grep $latest_filename | cut -d ' ' -f1)

        local ok=0
        local retries=0
        while [[ ${ok} -eq 0 && ${retries} -lt 3 ]]; do
            if [[ ! -f $cache_path ]]; then
                echo "Downloading '${latest_filename}' bit to cache." >&2
                $BUILDS_CURL --url $latest_path --progress-bar -o $cache_path \
                    || fatal "Unable to fetch '${latest_path}'."
            fi

            local my_md5
            my_md5=$(openssl dgst -md5 < ${cache_path} | awk '{print $NF}')
            if [[ ${my_md5} == ${md5} ]]; then
                ok=1
                continue
            else
                rm -f ${cache_path}
                retries=$((${retries} + 1))
                # BASHSTYLED
                echo "CORRUPT OR TRUNCATED ${cache_path}, deleted and trying again (attempt ${retries}/3)" >&2
            fi
        done
        if [[ ${ok} -ne 1 ]]; then
            # BASHSTYLED
            fatal "Unable to get non-corrupt version of ${cache_path} after ${retries} attempts."
        fi
        get_bit_rv=${cache_path}
        cleanup_bit "${file_name}"

        echo "${get_bit_rv}"
        return
    fi

    local latest_dir
    latest_dir="${base_path}/${pattern_dir}/${branch}-latest"
    local manta_base_dir
    manta_base_dir=$(mget ${latest_dir} 2>/dev/null)

    # Fallback to joyent_bits_base_path in case this is a private build
    if [[ -z ${manta_base_dir} && -n ${joyent_bits_base_path}
        && ${joyent_bits_base_path} != ${base_path} ]]; then

        base_path=${joyent_bits_base_path}
        latest_dir="${base_path}/${pattern_dir}/${branch}-latest"
        manta_base_dir=$(mget ${latest_dir} 2>/dev/null)
    fi

    [[ -n ${manta_base_dir} ]] \
        || fatal "get_manta_bit: unable to find manta_base_dir for ${file_name}"

    local manta_file_dir="${manta_base_dir}/${pattern_dir}"
    local latest_name
    latest_name=$(mfind ${manta_file_dir} | grep ${file_name})
    [[ -n ${latest_name} ]] \
        || fatal "get_manta_bit: unable to find latest_name for ${file_name}"
    local latest_filename
    latest_filename=$(basename $latest_name)
    [[ -n ${latest_filename} ]] \
        || fatal "get_manta_bit: unable to get latest_filename for ${file_name}"
    local cache_path=${ROOT}/cache/${latest_filename}

    local md5
    md5=$(mget ${manta_base_dir}/md5sums.txt 2>/dev/null \
                | grep $latest_filename | cut -d ' ' -f1)

    local ok=0
    local retries=0
    while [[ ${ok} -eq 0 && ${retries} -lt 3 ]]; do
        if [[ ! -f $cache_path ]]; then
            echo "Downloading '${latest_name}' bit to cache." >&2
            mget --progress -o ${ROOT}/cache/${latest_filename} ${latest_name} \
                || fatal "Unable to fetch '${latest_filename}'."
        fi

        local my_md5
        my_md5=$(openssl dgst -md5 < ${cache_path} | awk '{print $NF}')
        if [[ ${my_md5} == ${md5} ]]; then
            ok=1
            continue
        else
            rm -f ${cache_path}
            retries=$((${retries} + 1))
            # BASHSTYLED
            echo "CORRUPT OR TRUNCATED ${cache_path}, deleted and trying again (attempt ${retries}/3)" >&2
        fi
    done
    if [[ ${ok} -ne 1 ]]; then
        # BASHSTYLED
        fatal "Unable to get non-corrupt version of ${cache_path} after ${retries} attempts."
    fi
    get_bit_rv=${cache_path}
    cleanup_bit "${file_name}"

    echo "${get_bit_rv}"
}


function _check_vpn
{
    if [[ ${HAVE_INTERNET} == "true" ]]; then
        local host=${1##*//}
        ping -o -t 3 ${host} &> /dev/null
        local result=$?
        if [[ ${result} -ne 0 ]]; then
            echo "Can't ping ${host} (are you on the VPN?)"
            exit ${result}
        fi
    fi
}


function copy_platform
{
    [[ -z "${loops}" ]] && loops=0
    loops=$((${loops} + 1))
    [[ ${loops} -gt 2 ]] && fatal "Unable to download platform, looping!"

    # platform_file is optional, if specified, that platform will be used
    # instead of looking for the newest that matches platform-<release>
    local platform_file=$1
    local platform_release=$2
    local plat_suffix=""

    local image
    if [[ -z ${platform_file} ]]; then

        # Check for using a debug platform
        if [[ "$(build_spec debug-platform)" == "true" \
              || -n "$DEBUG_BUILD" ]]; then
            plat_suffix="-debug"
            echo "Using DEBUG platform"
        fi

        [[ -z "${platform_release}" ]] \
            && fatal "Must define 'platform_file' or 'platform_release' " \
                     "for call to 'copy_platform()'."

        # BASHSTYLED
        image=$(get_manta_bit "platform${plat_suffix}/${platform_release}/platform${plat_suffix}-${platform_release}-.*")

        if [[ -f ${image} ]] && ! valid_archive ${image}; then
            echo "Removing corrupt ${image}"
            rm -f ${image}
            image=
            # unset image and try again
            copy_platform "${platform_file}" "${platform_release}"
        fi
    else
        image=${platform_file}
        echo "==> Using ${image} as platform image"
        if ! valid_archive "${image}"; then
            fatal "Refusing to use corrupt platform ${image}"
        fi
    fi

    export USING_PLATFORM=${image}

    LIVEIMG_VERSION=`basename ${image} \
        | sed -e "s/platform.*-\([0-9TZ]*\)\.tgz/\1/"`

    echo "==> Unpacking `basename ${image}`"
    (set -e; cd ${STAGE}/; ${TAR} -zxf ${image}; \
        mkdir -p os/${LIVEIMG_VERSION}; \
        mv platform-* os/${LIVEIMG_VERSION}/platform) \
        || fatal "Unable to unpack platform"
    if [[ -f ${STAGE}/os/${LIVEIMG_VERSION}/platform/root.password ]]; then
        (cd ${STAGE}/ \
            && mkdir -p private \
            && mv -f os/${LIVEIMG_VERSION}/platform/root.password \
                private/root.password.${LIVEIMG_VERSION}) \
            || fatal "Unable to move root.password"
    fi
    root_pw=$(cat ${STAGE}/private/root.password.${LIVEIMG_VERSION})
    echo "Root password is: '${root_pw}'"

    # Create the menu.lst file
    cat ${STAGE}/boot/grub/menu.lst.tmpl | sed \
        -e "s|/PLATFORM/|/os/${LIVEIMG_VERSION}/platform/|" \
        > ${STAGE}/boot/grub/menu.lst

    rm -f ${LOGDIR}/latest
    ln -s ${LOGFILE} ${LOGDIR}/latest

    loops=
}


# Copy the latest 'sdcadm' build into the usbkey stage dir.
#
# "sdcadm-release" in build.spec[.local] is either a branch build (default is
# "master") or a full path to a sdcadm shar to use.
#
function copy_sdcadm
{
    [[ -z "${loops}" ]] && loops=0
    loops=$((${loops} + 1))
    [[ ${loops} -gt 2 ]] && fatal "Unable to download sdcadm, looping!"

    local path
    path=$(build_spec sdcadm-release)
    if [[ ! -f "${path}" ]]; then
        # Try 'sdcadm-release' as a branch.
        path=$(get_manta_bit "sdcadm/${path}/sdcadm-${path}-.*\.sh")
    fi

    echo "Copying $(basename $path) to \$stage/sdcadm-install.sh"
    cp ${path} ${STAGE}/sdcadm-install.sh

    loops=
}


function get_agentsshar
{
    [[ -z "${loops}" ]] && loops=0
    loops=$((${loops} + 1))
    [[ ${loops} -gt 2 ]] && fatal "Unable to download agents, looping!"

    local branch=$1

    if [[ -f ${branch} && -f ${branch/%sh/md5sum} ]]; then
        local agentsshar_path=${branch}
        local agentsmd5_path=${branch/%sh/md5sum}
    else
        local agentsshar_path
        agentsshar_path=$(get_manta_bit \
            "agentsshar/${branch}/agents-${branch}-.*\.sh")
        local agentsmd5_path
        agentsmd5_path=$(get_manta_bit \
            "agentsshar/${branch}/agents-${branch}-.*\.md5sum")
    fi

    # Make sure it's not corrupt.
    local MD5
    MD5=$(cat ${agentsmd5_path})
    local ACTUAL_MD5
    ACTUAL_MD5=$(openssl dgst -md5 ${agentsshar_path} | awk '{print $NF}')
    if [[ -z ${MD5} ]] \
        || [[ -z ${ACTUAL_MD5} ]] \
        || [[ ${MD5} != ${ACTUAL_MD5} ]]; then
        echo "Removing corrupt ${agentsshar_path}"
        rm -f ${agentsshar_path} ${agentsmd5_path}
        get_agentsshar ${agentsshar_branch}
    fi

    echo "Copying $(basename $agentsshar_path) to stage."
    mkdir -p ${STAGE}/ur-scripts
    cp ${agentsshar_path} ${STAGE}/ur-scripts/

    loops=
}

function copy_agentsshar
{
    # See if there's a specific agents shar we're supposed to use
    if [[ -z ${agentsshar_branch} ]]; then
        agentsshar_branch=$(build_spec agents-shar)
    fi

    if [[ -z ${agentsshar_branch} ]]; then
        agentsshar_branch="master"
    fi

    get_agentsshar ${agentsshar_branch}
}

function copy_sapi_config
{
    local manifests=${ROOT}/config/sapi/manifests/
    local services=${ROOT}/config/sapi/services/
    local application=${ROOT}/config/sapi/application.json
    NO_RABBIT=$(build_spec no-rabbit)

    cp -r ${manifests} ${STAGE}/manifests
    cp -r ${services} ${STAGE}/services
    if [[ "$NO_RABBIT" == "true" ]]; then
        cat "${application}" | ${ROOT}/bin/json -e \
            "this.metadata.no_rabbit = true;" > ${STAGE}/application.json
    else
        cp ${application} ${STAGE}/application.json
    fi
}

function copy_datasets
{
    mkdir -p ${STAGE}/datasets
    mkdir -p ${ROOT}/datasets

    datasets_json=$(build_spec datasets)

    [[ -n ${datasets_json} ]] \
        || fatal "Unable to find datasets information in build.spec"

    num_datasets=$(echo "${datasets_json}" | ${ROOT}/bin/json length)
    index=0
    while [[ ${index} -lt ${num_datasets} ]]; do
        imgapi=$(echo "${datasets_json}" | ${ROOT}/bin/json ${index}.imgapi)
        name=$(echo "${datasets_json}" | ${ROOT}/bin/json ${index}.name)
        uuid=$(echo "${datasets_json}" | ${ROOT}/bin/json ${index}.uuid)
        manifest_url=${imgapi}/images/${uuid}
        file_url=${imgapi}/images/${uuid}/file
        manifest="${ROOT}/cache/${name}.dsmanifest"

        if [[ ! -f $manifest ]] ; then
            if [[ -f ${ROOT}/datasets/${name}.dsmanifest ]]; then
                cp ${ROOT}/datasets/${name}.dsmanifest ${manifest}
            elif [[ ${HAVE_INTERNET} == "true" ]]; then
                echo "==> Downloading ${name} manifest (${manifest_url})"
                (curl ${CURL_OPTS} \
                    -ksSf -o ${manifest} ${manifest_url}) \
                    || fatal "Unable to download ${name} manifest"
            else
                fatal "Don't have required '${name}' manifest" \
                    "and can't download (no Internet)"
            fi
        fi

        compression_type=$(cat ${manifest} \
                           | ${ROOT}/bin/json files[0].compression)
        if [[ ${compression_type} == "bzip2" ]]; then
            compression=bz2
        elif [[ ${compression_type} == "gzip" ]]; then
            compression=gz
        else
            if [[ -n $(cat ${manifest} | ${ROOT}/bin/json files[0].path \
                  | grep ".gz$") ]]; then
                compression=gz
            elif [[ -n $(cat ${manifest} | ${ROOT}/bin/json files[0].path \
                    | grep ".bz2$") ]]; then
                compression=bz2
            fi
        fi

        if [[ -z ${compression} ]]; then
            fatal "Unable to determine compression for ${name}"
        fi

        local sha1
        sha1=$(cat ${manifest} | ${ROOT}/bin/json files[0].sha1)
        copy_dataset ${name} ${file_url} ${sha1} ${name}.zfs.${compression}
        cp ${manifest} ${STAGE}/datasets/$(basename ${manifest})

        echo "${name}" >> ${STAGE}/datasets/img_dependencies

        index=$((${index} + 1))
    done
}

# This is temporary, until we have all the SDC datasets at the same place.
# It might be good anyway to add a little check to verify arguments are given.
function copy_dataset
{
  local dataset=$1
  local dataset_uri=$2
  local dataset_sha1=$3
  local dataset_file=$4

  if [ -e ${ROOT}/cache/${dataset_file} ]; then
    if [[ ${dataset_file} =~ gz$ ]]; then
        if ! gzip -t ${ROOT}/cache/${dataset_file}; then
            echo "==> Corrupt ${dataset_file}, deleting..."
            rm -f ${ROOT}/cache/${dataset_file}
        fi
    elif ! bzip2 -t ${ROOT}/cache/${dataset_file}; then
        echo "==> Corrupt ${dataset_file}, deleting..."
        rm -f ${ROOT}/cache/${dataset_file}
    fi
  fi

  if [[ ! -f ${ROOT}/cache/${dataset_file} ]]; then
      if [[ ${HAVE_INTERNET} == "true" ]]; then
          echo "==> Downloading ${dataset_file}"
          (cd ${ROOT}/cache && curl ${CURL_OPTS} -kf \
              -o ${dataset_file} ${dataset_uri}) \
              || fatal "Unable to download ${dataset_file}"
      else
          fatal "Don't have Internet, and don't have valid " \
              "${dataset_file}. Can't build."
      fi
  fi

  local cached_dataset_sha1
  cached_dataset_sha1=$(${SUM} ${ROOT}/cache/${dataset_file} | awk '{print $1}')
  if [[ ${cached_dataset_sha1} != ${dataset_sha1} ]]; then
    rm -f ${ROOT}/cache/${dataset_file}
    # BASHSTYLED
    fatal "Corrupt ${dataset_file} (doesn't match sha1 in manifest), deleted! Try build again."
  fi

  echo "==> Copying image ${dataset_file} to 'datasets/'."
  ln ${ROOT}/cache/${dataset_file} ${STAGE}/datasets/${dataset_file}
}

# Get the image manifest and file for the given core SDC zone.
#
# Usage:
#   get_core_zone_image ZONE TARGET DST-DIR
#
# where:
# - "TARGET" is either a full path to an existing image manifest file
#   or (more typically) a pattern used by the "get_bit" function for getting
#   a manifest file from the MG builds area on bits.joyent.us.
#
# Examples:
#   get_core_zone_image admin "adminui/adminui-zfs-.*manifest" \
#           /home/trent/usb-headnode/cache/stage/datasets
#
function get_core_zone_image
{
    local zone=$1
    local target=$2
    local dst_dir=$3

    if [[ -z "${target}" ]]; then
        # BASHSTYLED
        fatal "get_core_zone_image(): empty target for zone '$zone' (Is '$zone-image' set in build.spec?)"
    fi
    if [[ -z "${dst_dir}" ]] || [[ ! -d ${dst_dir} ]]; then
        # BASHSTYLED
        fatal "get_core_zone_image(): No destination dir specified or not a directory."
    fi

    # First get it and cache it. Then we'll copy it to $dst_dir.
    local manifest_base dst_manifest dst_file
    if [[ -f ${target} ]]; then
        # Existing local file. Use that.
        # XXX Normalize to '.imgmanifest' ext, which will be the eventual
        #     usage but is '.dsmanifest' in the builds at this time.
        manifest_base=$(basename $target)
        dst_manifest=${dst_dir}/${manifest_base%.*}.imgmanifest
        if [[ "${target}" != "${dst_manifest}" ]]; then
            ln ${target} ${dst_manifest}
        fi
        local src_file
        src_file=$(ls -1 ${target%.*}* | grep -v 'manifest$')
        dst_file=${dst_dir}/$(basename $src_file)
        ln ${src_file} ${dst_file}
        clean_pattern=$(echo "$(basename $dst_file)" \
                        | sed -e 's/^\(.*-zfs-[^\-]*-\).*\(\.zfs.*\)$/\1.*\2/')
        cleanup_bit ${clean_pattern}
    else
        # Not a local file, this is a pattern for 'get_bit'.
        local bit_cache_path
        bit_cache_path=$(get_manta_bit ${target})
        # XXX Normalize to '.imgmanifest' ext, which will be the eventual
        #     usage but is '.dsmanifest' in the builds at this time.
        manifest_base=$(basename $bit_cache_path)
        dst_manifest=${dst_dir}/${manifest_base%.*}.imgmanifest
        rm -f ${dst_manifest}
        ln ${bit_cache_path} ${dst_manifest}
        # BEGIN BASHSTYLED
        # Example of getting get_bit pattern for the image *file*:
        #   target 'adminui/adminui-zfs.*manifest'
        #   bit_cache_path '/.../cache/adminui-zfs-master-20130401T104924Z-g1695958.zfs.imgmanifest'
        #   -> file_pattern 'adminui/adminui-zfs-master-20130401T104924Z-g1695958.zfs.gz'
        # Note: We are hardcoding that sdc images use gzip compression here.
        # END BASHSTYLED
        local file_pattern=${target%/*}/${manifest_base%.*manifest}.*.gz
        bit_cache_path=$(get_manta_bit $file_pattern)
        dst_file=${dst_dir}/$(basename $bit_cache_path)
        rm -f ${dst_file}
        ln ${bit_cache_path} ${dst_file}
        gzip -t ${dst_file} \
            || fatal "Corrupt ${dst_file}, please remove and re-run."
        clean_pattern=$(echo "$(basename $bit_cache_path)" \
                        | sed -e 's/^\(.*-zfs-[^\-]*-\).*\(\.zfs.*\)$/\1.*\2/')
        cleanup_bit ${clean_pattern}
    fi

    # HEAD-1371 - insert image uuid into config/services/${zone}/service.json
    # as param. Expect an IMAGE_UUID placeholder.
    local service=${STAGE}/services/${zone}/service.json
    if [[ -f ${service} ]]; then
        local image_uuid
        image_uuid=$(cat ${dst_manifest} | ${ROOT}/bin/json uuid)
        sed -i'.tmp' -e "s|IMAGE_UUID|${image_uuid}|" ${service}
        rm ${service}.tmp
    fi

    # PCFS, sigh.
    echo $(basename $dst_manifest) | tr '[:upper:]' '[:lower:]' \
        > ${STAGE}/zones/${zone}/dataset
}

function copy_zones
{
    for zone in $(ls ${STAGE}/zones); do

        # Symlinks aren't supported on pcfs, so we copy the files
        if [[ -L ${ROOT}/zones/${zone}/backup ]]; then
            rm ${STAGE}/zones/${zone}/backup
            cp ${ROOT}/zones/${zone}/backup ${STAGE}/zones/${zone}/backup
        fi
        if [[ -L ${ROOT}/zones/${zone}/restore ]]; then
            rm ${STAGE}/zones/${zone}/restore
            cp ${ROOT}/zones/${zone}/restore ${STAGE}/zones/${zone}/restore
        fi

        local image_pattern
        image_pattern=$(build_spec ${zone}-image)
        mkdir -p ${STAGE}/datasets
        get_core_zone_image "${zone}" "${image_pattern}" ${STAGE}/datasets
    done
}

function copy_tools
{
    if [[ ! -f ${ROOT}/tools.tar.gz ]]; then
        fatal "could not find tools.tar.gz; did 'make tools.tar.gz' run?"
    fi
    if [[ ! -f ${ROOT}/cn_tools.tar.gz ]]; then
        fatal "could not find cn_tools.tar.gz; did " \
            "'make cn_tools.tar.gz' run?"
    fi
    cp ${ROOT}/tools.tar.gz ${STAGE}/tools.tar.gz
    cp ${ROOT}/cn_tools.tar.gz ${STAGE}/cn_tools.tar.gz
}

function copy_to_mount
{
    echo "${THIS_BUILDSTAMP}" > ${STAGE}/version

    (cd ${STAGE} && ${TAR} ${TAR_ROOT} -cf - * .[a-zA-Z]*) \
        | (cd ${MNT_DIR} && ${SUCMD} ${TAR} --no-same-owner -xvf -) \
        || fatal "Unable to copy files to mount"
}

function add_manifests
{
    # build manifest of USB files + move in boot_archive manifest
    rm -f $STAGE/usb_key.manifest || true
    (cd ${STAGE}/ \
        && find . -type f -exec openssl dgst -md5 {} \; | awk '{print $NF}') \
        > $STAGE/usb_key.manifest
    [[ $? -eq 0 ]] || fatal "Unable to add manifests"
    rm -f $STAGE/boot_archive.manifest || true

    # BASHSTYLED
    cp ${STAGE}/os/${LIVEIMG_VERSION}/platform/i86pc/amd64/boot_archive.manifest \
        $STAGE/boot_archive.manifest
    chmod 444 $STAGE/*.manifest
}

# Main()

check_nodejs
test_rootperms

create_directories
load_buildspec
copy_base
generate_grub_menu
copy_platform "${PLATFORM_FILE}" "${PLATFORM_RELEASE}"
copy_sdcadm
copy_agentsshar
copy_sapi_config
copy_datasets
copy_zones
copy_tools
copy_config

unpack_image
add_manifests
mount_image
trap 'cleanup' EXIT
copy_to_mount
cleanup
create_output
cleanup_logs

# Unfortunately the log contains a whole bunch of progress updates,
# clean that up.
if [[ -f ${LOGFILE} ]]; then
    cat ${LOGFILE} | ${GREP} -v "
" > ${LOGFILE}.tmp \
    && mv ${LOGFILE}.tmp ${LOGFILE}
fi

if [ ${ERROR} -ne 0 ]; then
    fatal "==> SOMETHING WENT WRONG! ERROR: ${ERROR}"
fi

echo "==> DONE"

exit 0
