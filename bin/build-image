#!/bin/bash
#
# Copyright (c) 2010,2011 Joyent Inc., All rights reserved.
#

#
# We set errexit (a.k.a. "set -e") to force an exit on error conditions, but
# there are many important error conditions that this does not capture --
# first among them failures within a pipeline (only the exit status of the
# final stage is propagated).  To exit on these failures, we also set
# "pipefail" (a very useful option introduced to bash as of version 3 that
# propagates any non-zero exit values in a pipeline).
#


set -o errexit
set -o pipefail

# write output to log file
ROOT=$(cd $(dirname $0)/../; pwd)
LOGDIR="${ROOT}/log"
LOGFILE="${LOGDIR}/build.log.$(date +%Y-%m-%d-%H-%M-%S).$$"
TAR=tar
GREP=grep
if [[ `uname -s` == 'SunOS' ]]; then
  SUM='/usr/bin/sum -x sha1'
else
  SUM='shasum'
fi


mkdir -p log
exec > >(tee ${LOGFILE}) 2>&1

if [[ $(echo $BASH_VERSION | cut -d '.' -f1-2) > 4.0 ]]; then
    BASH_IS_NOT_ANCIENT='true'
fi

#export PS4='${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
#set -x

if [[ `hostname` == "bh1-autobuild" || `hostname` == "bldzone2.joyent.us" || ! -z $BASH_IS_NOT_ANCIENT ]]; then
    export PS4='${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
    export BASH_XTRACEFD=4
    set -o xtrace
fi

THIS_BRANCH=$(git symbolic-ref HEAD | cut -d'/' -f3)

THIS_VERSION=$(date -u +%Y%m%dT%H%M%SZ).${THIS_BRANCH}-$(git describe)

if [ -f build-number.txt ]; then
    THIS_VERSION="${THIS_VERSION}-$(cat build-number.txt \
        | sed -n 's,^build\.number=\(.*\),\1,p')"
fi

RECIPE=$(pwd)/recipe.${THIS_VERSION}

echo ">> Starting build at $(date)"

function fatal
{
    echo "$(basename $0): fatal error: $*"
    exit 1
}

function errexit
{
    [[ $1 -ne 0 ]] || exit 0
    fatal "error exit status $1 at line $2"
}

function check_nodejs
{
    [[ ! `which node` ]] && fatal "build-image requires node to be in your path"

    ver=`node --version`
    micro=${ver##*.}
    front=${ver%.*}
    minor=${front##*.}

    [[ $minor -ne 4 ]] && fatal "Node minor version must be 4"
    [[ $micro -lt 9 ]] && fatal "Node micro version must be at least 9"

    if [[ $(echo '{"foo": "bar"}' | ${ROOT}/bin/json foo) == 'bar' ]]; then
        echo "Your version of node.js is ok!"
    else
        fatal "You need to have a working node.js installed for this to work!"
    fi
}

function check_npm
{

    if [[ ! `which npm` ]] || [[ `npm -v` != 1\.* ]]; then
	echo "build-image requires npm 1.0.x to be in your path"
	exit 1
    fi
}

function check_proxy
{
    # See https://hub.joyent.com/wiki/display/dev/proxy-usb-headnode
    if [[ -f "${ROOT}/build.spec" ]]; then
        if [[ -z ${USE_PROXY} ]]; then
            USE_PROXY=$(cat ${ROOT}/build.spec \
                | ${ROOT}/bin/json use-proxy)
        fi
        if [[ -z ${PROXY_IP} ]]; then
            PROXY_IP=$(cat ${ROOT}/build.spec \
                | ${ROOT}/bin/json proxy-ip)
        fi
    fi
    if [[ -f "${ROOT}/build.spec.local" ]]; then
        USE_PROXY=$(cat ${ROOT}/build.spec.local \
            | ${ROOT}/bin/json use-proxy)
        PROXY_IP=$(cat ${ROOT}/build.spec.local \
            | ${ROOT}/bin/json proxy-ip)
    fi

    if [[ -n ${USE_PROXY} && ${USE_PROXY} == "false" ]]; then
        NOPROXY="true"
    fi
    if [[ -z ${PROXY_IP} ]]; then
        NOPROXY="true"
    fi

    if [ -z "$NOPROXY" -a -z "$NOINTERNET" ]; then
      if netstat -rn | grep -q 10\.0\.1\.1 ; then
        echo "Checking for proxy"
        PROXY=`curl ${CURL_OPTS} -m 1 -s \
            http://${PROXY_IP}/proxy-usb-headnode/location 2> /dev/null || true`
        if [ "$PROXY" == "vancouver" ]; then
          echo "Vancouver proxy found."
        elif [ -n "$PROXY" ]; then
          echo "Unknown proxy: $PROXY"
        else
          echo "No proxy found."
        fi
      fi
    else
        echo "Proxy disabled."
    fi
}

function proxy
{
    # See https://hub.joyent.com/wiki/display/dev/proxy-usb-headnode

    if [ "$PROXY" = "vancouver" ]; then

      # Sorry about the gnarly regexes - we want to generate URLs that look like:
      #
      # /https/guest_GrojhykMid@coal.joyent.us/coal/live_147
      # /http/guest_GrojhykMid@10.0.1.8/platform
      # /http/pkgsrc.joyent.com/sdc/2010Q4/gcc45/All
      # /https/guest_GrojhykMid@216.57.203.68/coal/live_147/agents

      PROTO=$(echo $1 | sed -E 's,^(https|http)://([^/]*)(/.*)?$,\1,')
      HOST=$(echo $1 | sed -E 's,^(https|http)://([^/]*)(/.*)?$,\2,' | tr : _)
      FILEPATH=$(echo $1 | sed -E 's,^(https|http)://([^/]*)(/.*)?$,\3,')
      echo "http://${PROXY_IP}/proxy-usb-headnode/${PROTO}/${HOST}${FILEPATH}"
    else
      echo $1
    fi
}

trap 'errexit $? $LINENO' EXIT

STAGE="${ROOT}/cache/stage"
ERROR=0
CLEANED=0

CURL_OPTS=
SPEED_LIMIT=
if [[ -f "${ROOT}/build.spec" ]]; then
    if [[ -z ${NO_INTERNET} ]]; then
        NO_INTERNET=$(cat ${ROOT}/build.spec \
            | ${ROOT}/bin/json no-internet)
    fi
    if [[ -z ${SPEED_LIMIT} ]]; then
        SPEED_LIMIT=$(cat ${ROOT}/build.spec \
            | ${ROOT}/bin/json speed-limit)
    fi
    if [[ -z ${CURL_OPTS} ]]; then
        CURL_OPTS=$(cat ${ROOT}/build.spec \
            | ${ROOT}/bin/json curl-opts)
    fi
fi
if [[ -f "${ROOT}/build.spec.local" ]]; then
    NO_INTERNET=$(cat ${ROOT}/build.spec.local \
        | ${ROOT}/bin/json no-internet)
    SPEED_LIMIT=$(cat ${ROOT}/build.spec.local \
        | ${ROOT}/bin/json speed-limit)
    CURL_OPTS=$(cat ${ROOT}/build.spec.local \
        | ${ROOT}/bin/json curl-opts)
fi


if [[ -n ${SPEED_LIMIT} ]]; then
    CURL_OPTS="${CURL_OPTS} --limit-rate ${SPEED_LIMIT}"
fi

check_proxy



# Determine from where to get dependent packages.
if [[ -z "$MASTER_PLATFORM_URL"  && -f ${ROOT}/build.spec.local ]]; then
    MASTER_PLATFORM_URL=$(cat ${ROOT}/build.spec.local \
                | ${ROOT}/bin/json master-url)
fi

if [[ -z "$MASTER_PLATFORM_URL" ]]; then
    MASTER_PLATFORM_URL=$(cat ${ROOT}/build.spec \
                | ${ROOT}/bin/json master-url)
fi
if [[ -z "$MASTER_PLATFORM_URL" ]]; then
    if [[ `echo $THIS_BRANCH | grep 'release'` ]]; then
      RELEASEDATE=$(echo $BRANCH | cut -d '-' -f2)
      RELEASEDIR=${releasedate:0:4}-${releasedate:4:2}-${releasedate:6:2}
      MASTER_REPO="https://guest:GrojhykMid@216.57.203.68/coal/releases/${RELEASE_DIR}/deps/"
      MASTER_PLATFORM_URL=$(proxy "${MASTER_REPO}")
    else
      MASTER_REPO="https://guest:GrojhykMid@216.57.203.68"
      MASTER_PLATFORM_URL=$(proxy "${MASTER_REPO}/coal/live_147")
    fi
fi
if [[ -z "$MASTER_PLATFORM_URL" ]]; then
    MASTER_PLATFORM_URL=https://guest:GrojhykMid@216.57.203.66:444/coal/live_147
fi
MASTER_PLATFORM_URL=$(proxy "$MASTER_PLATFORM_URL")

#TODO(trent): Is anyone setting PLATFORM_URL for builds? If not drop the alias.
if [ -z "${PLATFORM_URL}" ]; then
    PLATFORM_URL=${MASTER_PLATFORM_URL}
fi
# See <https://hub.joyent.com/wiki/display/doc/Special+CAPI+Accounts> for
# details on user used with DSAPI.
DSAPI_URL=$(proxy "https://usbheadnode:shnek7bi3op5@datasets.joyent.com")
PKGSRC_ROOT=$(proxy "http://pkgsrc.joyent.com/sdc/2010Q4/gcc45/All/")
AGENTS_BASE=$(proxy "${MASTER_PLATFORM_URL}/agents")
ASSETS_ROOT=$(proxy "${MASTER_PLATFORM_URL}/assets")



# Figure out first what we're building, and load the proper include

PLATFORM=$(uname -s)

if [[ $1 == "-r" ]]; then
    shift
    RECIPE=$1
    # Turn relative paths in to absolute paths
    if [[ -z $(dirname $RECIPE | grep ^/) ]]; then
        RECIPE=$(pwd)/$RECIPE
    fi
    REBUILD_FROM_RECIPE=1
    shift
    echo "Rebuilding from ${RECIPE}..."
    if [[ ! -f $RECIPE ]]; then
        echo "Could not find rebuild recipe file..."
        exit 1
    fi
fi

NO_CONFIG_FILE=0
if [[ $1 == "-c" ]]; then
    shift
    NO_CONFIG_FILE=1
    echo "Building with no config file in the image. "
fi

BUILD_TYPE=$1
if [[ -z ${BUILD_TYPE} ]]; then
    BUILD_TYPE="coal"
fi
if [[ ${PLATFORM} == 'Darwin' ]]; then
    case ${BUILD_TYPE} in
        vmware|coal)
            source ${ROOT}/bin/include-coal-osx
            version
            ;;
        usb)
            source ${ROOT}/bin/include-usb-osx
            version
            ;;
        upgrade)
            ONLY_UPGRADE=true
            source ${ROOT}/bin/include-tar-generic
            version
            echo "==> Building upgrade image"
            ;;
        tar)
            source ${ROOT}/bin/include-tar-generic
            version
            ;;
        *)
            fatal  "FATAL: Unsupported build type on OSX: ${BUILD_TYPE}"
            ;;
    esac
elif [[ ${PLATFORM} == 'Linux' ]]; then
    case ${BUILD_TYPE} in
        coal)
            source ${ROOT}/bin/include-vmware-linux
            version
            ;;
        vmware)
            source ${ROOT}/bin/include-vmware-linux
            version
            ;;
        usb)
            echo "Linux-usb";
            exit 0
            ;;
        upgrade)
            ONLY_UPGRADE=true
            source ${ROOT}/bin/include-tar-generic
            version
            echo "==> Building upgrade image"
            ;;
        tar)
            source ${ROOT}/bin/include-tar-generic
            version
            ;;
        *)
            fatal "FATAL: Unsupported build type on Linux: ${BUILD_TYPE}"
            ;;
    esac
elif [[ ${PLATFORM} == 'SunOS' ]]; then
    case ${BUILD_TYPE} in
        usb)
            source ${ROOT}/bin/include-usb-smartos
            version
            ;;
        coal)
            source ${ROOT}/bin/include-coal-smartos
            version
            ;;
        upgrade)
            ONLY_UPGRADE=true
            source ${ROOT}/bin/include-tar-generic
            version
            echo "==> Building upgrade image"
            ;;
        tar)
            source ${ROOT}/bin/include-tar-generic
            version
            ;;
        *)
            fatal "FATAL: Unsupported build type on SmartOS: ${BUILD_TYPE}"
            ;;
    esac
else
    echo "FATAL: Unsupported platform '${PLATFORM}'"
fi

echo -n "==> Checking for Internets... "
if [[ ${NO_INTERNET} == "true" ]] || ! can_has_internets; then
    echo "No Internets! Activating countermeasures!"
    HAVE_INTERNET="false"
else
    echo "Yep!"
    HAVE_INTERNET="true"
fi

function test_rootperms
{
    su_uid=$(${SUCMD} id -u)
    if [[ ${su_uid} -ne 0 ]]; then
        fatal "Can't get root priviledges."
    fi
}

function load_buildspec
{
    # local is read first and options are only read from build.spec
    # only if they're not set in build.spec.local
    if [[ -f "${ROOT}/build.spec.local" ]]; then
        PLATFORM_RELEASE=$(cat ${ROOT}/build.spec.local \
            | ${ROOT}/bin/json platform-release)
        BUILD_TGZ=$(cat ${ROOT}/build.spec.local \
            | ${ROOT}/bin/json build-tgz)
    fi

    if [[ -f "${ROOT}/build.spec" ]]; then
        if [[ -z ${PLATFORM_RELEASE} ]]; then
            PLATFORM_RELEASE=$(cat ${ROOT}/build.spec \
                | ${ROOT}/bin/json platform-release)
        fi
        if [[ -z ${BUILD_TGZ} ]]; then
            BUILD_TGZ=$(cat ${ROOT}/build.spec \
                | ${ROOT}/bin/json build-tgz)
        fi
    fi
    [[ -n ${PLATFORM_RELEASE} ]] && echo "platform-release: ${PLATFORM_RELEASE}"
}

function create_directories
{
    if [ ! -d "${ROOT}/cache" ]; then
        echo "==> Creating cache/"
        mkdir -p ${ROOT}/cache
    fi

    if [ ! -d "${ROOT}/mnt" ]; then
        echo "==> Creating mnt/"
        mkdir -p ${ROOT}/mnt
    fi

    echo "==> Creating stage/"
    rm -rf ${STAGE}
    mkdir -p ${STAGE}
    mkdir -p ${STAGE}/data
}

function copy_base
{
    echo "==> Creating .joyliveusb file"
    touch ${STAGE}/.joyliveusb

    echo "==> Copying in grub menu"
    mkdir -p ${STAGE}/boot/grub
    cp boot/grub/menu.lst.tmpl ${STAGE}/boot/grub/menu.lst.tmpl
    cp boot/grub/stage2 ${STAGE}/boot/grub/stage2
    cp boot/splash.xpm.gz ${STAGE}/boot/splash.xpm.gz

    echo "==> Copying in config"
    if [[ -n ${IMG_TYPE} ]] && [[ "${IMG_TYPE}" == "coal" ]]; then
        if [[ ${NO_CONFIG_FILE} == 0 ]]; then
            if [[ -f config/config.coal.local ]]; then
              cp config/config.coal.local ${STAGE}/config
            else
              cp config/config.coal ${STAGE}/config
            fi
        fi

        if [[ -d config/config.coal.inc.local ]]; then
            cp -r config/config.coal.inc.local ${STAGE}/config.inc
        else
            cp -r config/config.coal.inc ${STAGE}/config.inc
        fi
    else
        if [[ ${NO_CONFIG_FILE} == 0 ]]; then
            if [[ -f config/config.usb.local ]]; then
              cp config/config.usb.local ${STAGE}/config
            else
              cp config/config.usb ${STAGE}/config
            fi
        fi

        if [[ -d config/config.usb.inc.local ]]; then
            cp -r config/config.usb.inc.local ${STAGE}/config.inc
        else
            cp -r config/config.usb.inc ${STAGE}/config.inc
        fi
    fi

    echo "==> Copying in scripts/"
    cp -r scripts ${STAGE}/scripts

    echo "==> Copying in zoneinit/"
    cp -r zoneinit ${STAGE}/zoneinit

    echo "==> Copying in zones/"
    cp -r zones ${STAGE}/zones

    echo "==> Copying in rc/"
    cp -r rc ${STAGE}/rc
}

function copy_pkgsrc
{
    if [[ ${HAVE_INTERNET} == "true" ]]; then
        (cd ${ROOT}/cache \
            && rm -f md5sums.txt \
            && curl ${CURL_OPTS} -O ${PKGSRC_ROOT}/md5sums.txt) \
            || fatal "Failed to download ${PKGSRC_ROOT}/md5sums.txt"
    elif [[ ! -f ${ROOT}/cache/md5sums.txt ]]; then
        fatal "Don't have cached md5sums.txt file, can't build. " \
            "You need to find some Internet."
    fi
    pkgs=$(cat ${ROOT}/zones/*/pkgsrc \
        | xargs -n1 \
        | sort \
        | uniq \
        | sed -e "s/$/.tgz/")
    for pkgfile in $pkgs; do
        MD5=$(${GREP} " ${pkgfile}" ${ROOT}/cache/md5sums.txt | cut -d' ' -f1 || true)
        if [[ -z ${MD5} ]]; then
            fatal "Unable to find md5sum for ${pkgfile}, " \
                "must be fixed before we can continue."
        fi

        [[ -f ${ROOT}/cache/${pkgfile} ]] \
            && ACTUAL_MD5=$(${MD5CMD} ${ROOT}/cache/${pkgfile} | cut -d' ' -f1)

        if [[ ! -f ${ROOT}/cache/${pkgfile} ]] \
            || [[ -z ${ACTUAL_MD5} ]] \
            || [[ ${MD5} != ${ACTUAL_MD5} ]]; then

            echo "==> Downloading ${pkgfile}"
            # if this exists, it's corrupt
            rm -f ${ROOT}/cache/${pkgfile}
            if [[ ${HAVE_INTERNET} == "true" ]]; then
                (cd ${ROOT}/cache \
                    && curl ${CURL_OPTS} \
                    -k -fO ${PKGSRC_ROOT}/${pkgfile}) \
                    || fatal "could not download ${PKGSRC_ROOT}/${pkgfile}"
            else
                fatal "Need Internet to download ${pkgfile}"
            fi
        else
            echo "==> Not downloading ${pkgfile} as existing file matches MD5"
        fi
    done

    echo "==> Creating pkgsrc.tar"
    (cd ${ROOT}/cache && ${TAR} -cvf ${STAGE}/data/pkgsrc.tar ${pkgs})
}

function valid_tgz_archive
{
    filename=$1
    if [[ -f ${filename} ]] && ${TAR} -ztf ${filename} > /dev/null; then
        return 0
    else
        return 1
    fi
}

function valid_archive
{
    filename=$1
    if [[ -f ${filename} ]] && ${TAR} -tf ${filename} > /dev/null; then
        return 0
    else
        return 1
    fi
}

function copy_platform
{
    [[ -z "${loops}" ]] && loops=0
    loops=$((${loops} + 1))
    [[ ${loops} -gt 2 ]] && fatal "Unable to download platform, looping!"

    # platform_file is optional, if specified, that platform will be used
    # instead of looking for the newest that matches platform-<release>
    platform_file=$1
    platform_release=$2

    # If master is "true" this platform is the one we'll use as the headnode's
    # platform, so we install it for that.  If not, we'll just copy to data dir
    master=$3

    # If platform_subdir is set, we look in that dir under PLATFORM_URL
    platform_subdir="/$4"
    if [[ ${platform_subdir} == '/' ]]; then
        platform_subdir=
    fi

    valid_platform="false"
    if [[ -z ${platform_file} ]]; then
        [[ -z "${platform_release}" ]] \
            && fatal "Must define 'platform_file' or 'platform_release' " \
                     "for call to 'copy_platform()'."
        if [[ ${HAVE_INTERNET} == "true" ]]; then
            latest_image=$(curl ${CURL_OPTS} -k -sS \
                ${PLATFORM_URL}${platform_subdir}/ \
                | ${GREP} "href=\"platform-${platform_release}*" \
                | cut -d'"' -f2 | sort | tail -1)
            if [[ ! -f "${ROOT}/cache/${latest_image}" ]]; then
                echo "==> Downloading ${latest_image}"
                (cd ${ROOT}/cache \
                  && curl ${CURL_OPTS} \
                  -k -O ${PLATFORM_URL}${platform_subdir}/${latest_image}) \
                  || fatal "Unable to download ${PLATFORM_URL}${platform_subdir}/${latest_image}"
            fi
        else
            latest_image=$(cd ${ROOT}/cache \
                && ls platform-${platform_release}-*.tgz | head -1)
            if [[ -z ${latest_image} ]]; then
                fatal "Unable to find a platform image and we have no Internet."
            fi
        fi

        image=${ROOT}/cache/${latest_image}
        if [[ -f ${image} ]] && ! valid_archive ${image}; then
            echo "Removing corrupt ${image}"
            rm -f ${image}
            image=
            # unset image and try again
            copy_platform "${platform_file}" "${platform_release}" "${master}" "${platform_subdir}"
        fi
    else
        image=${platform_file}
        echo "==> Using ${image} as platform image"
        if ! valid_archive "${image}"; then
            fatal "Refusing to use corrupt platform ${image}"
        fi
    fi

    if [[ -z ${master} || ${master} != "true" ]]; then
        cp ${image} ${STAGE}/data/
    else
        export USING_PLATFORM=${image}

        LIVEIMG_VERSION=`basename ${image} \
            | sed -e "s/platform.*-\([0-9TZ]*\)\.tgz/\1/"`

        echo "==> Unpacking `basename ${image}`"
        (cd ${STAGE}/; ${TAR} -zxf ${image}; mkdir -p os/${LIVEIMG_VERSION}; \
            mv platform-* os/${LIVEIMG_VERSION}/platform) \
            || fatal "Unable to unpack platform"
        if [[ -f ${STAGE}/os/${LIVEIMG_VERSION}/platform/root.password ]]; then
            (cd ${STAGE}/ \
                && mkdir -p private \
                && mv -f os/${LIVEIMG_VERSION}/platform/root.password \
                    private/root.password.${LIVEIMG_VERSION}) \
                || fatal "Unable to move root.password"
        fi
        root_pw=$(cat ${STAGE}/private/root.password.${LIVEIMG_VERSION})
        echo "Root password is: '${root_pw}'"

        # Create the menu.lst file

        cat ${STAGE}/boot/grub/menu.lst.tmpl | sed \
            -e "s|/PLATFORM/|/os/${LIVEIMG_VERSION}/platform/|" \
            > ${STAGE}/boot/grub/menu.lst

        # Rename log file here since we know the buildstamp now
        mv ${LOGFILE} ${LOGDIR}/build.log.${LIVEIMG_VERSION}
        LOGFILE="${LOGDIR}/build.log.${LIVEIMG_VERSION}"
        rm -f ${LOGDIR}/latest
        ln -s ${LOGFILE} ${LOGDIR}/latest
    fi

    loops=
}

function get_agents
{
    [[ -z "${loops}" ]] && loops=0
    loops=$((${loops} + 1))
    [[ ${loops} -gt 2 ]] && fatal "Unable to download agents, looping!"

    # We treat agents_shar as a pattern and grab the latest one which matches
    agents_shar=$1

    # if agents_subdir is set, pull agents from that dir
    agents_subdir="/$2"
    if [[ ${agents_subdir} == '/' ]]; then
        agents_subdir=
    fi

    # Figure out for sure which one we want
    if [[ ${HAVE_INTERNET} == "true" ]]; then
        latest_agents=$(curl ${CURL_OPTS} \
            -k -sS ${MASTER_PLATFORM_URL}/ur-scripts${agents_subdir}/ \
            | ${GREP} "href=\"agents" \
            | ${GREP} "${agents_shar}" \
            | cut -d'"' -f2 | sort | tail -1)
    else
        latest_agents=$(cd ${ROOT}/cache \
            && ls agents-*.sh \
            | ${GREP} "${agents_shar}" \
            | tail -1)
    fi
    if [[ -z ${latest_agents} ]]; then
        fatal "Unable to find latest agents!"
    fi
    use_agents=${latest_agents}
    if [[ ! -z ${AGENTS_SHAR_OVERRIDE} ]]; then
        use_agents=$(basename ${AGENTS_SHAR_OVERRIDE})
        cp $(dirname ${AGENTS_SHAR_OVERRIDE})/$(basename $use_agents .sh).* ${ROOT}/cache/
    fi
    if [[ -z ${use_agents} ]]; then
        fatal "Unable to determine which agents to use!"
    fi

    echo "Using agents: [${use_agents}]"

    if [[ ! -f "${ROOT}/cache/${use_agents}" ]] \
        || [[ ! -f "${ROOT}/cache/`basename ${use_agents} .sh`.md5sum" ]]; then
        if [[ ${HAVE_INTERNET} == "true" ]]; then
            echo "==> Downloading ${use_agents}"

            AGENT_URL_BASE="${MASTER_PLATFORM_URL}/ur-scripts${agents_subdir}"
            AGENT_URL="${AGENT_URL_BASE}/${use_agents}"
            AGENT_MD_URL="${AGENT_URL_BASE}/`basename ${use_agents} .sh`.md5sum"

            (cd ${ROOT}/cache && curl ${CURL_OPTS} \
                -k -O ${AGENT_URL}) \
                || fatal "Unable to download ${AGENT_URL}"
            (cd ${ROOT}/cache && curl ${CURL_OPTS} \
                -k -O ${AGENT_MD_URL}) \
                || fatal "Unable to download ${AGENT_MD_URL}"
        else
            fatal "Don't have required '${use_agents}' " \
                "and can't download (no Internet)"
        fi
    fi

    mkdir -p ${STAGE}/ur-scripts

    # Make sure it's not corrupt
    if [[ -n "${use_agents}" ]] \
        && [[ -f "${ROOT}/cache/${use_agents}" ]] \
        && [[ -f "${ROOT}/cache/`basename ${use_agents} .sh`.md5sum" ]]; then

        # Check the md5sum
        MD5=$(cat ${ROOT}/cache/`basename ${use_agents} .sh`.md5sum)
        ACTUAL_MD5=$(${MD5CMD} ${ROOT}/cache/${use_agents} | cut -d' ' -f1)

        if [[ -z ${MD5} ]] \
            || [[ -z ${ACTUAL_MD5} ]] \
            || [[ ${MD5} != ${ACTUAL_MD5} ]]; then

            echo "Removing corrupt ${use_agents}"
            rm -f ${ROOT}/cache/${use_agents} \
                ${ROOT}/cache/`basename ${use_agents} .sh`.md5sum
            use_agents=
            get_agents ${agents_shar} "${agents_subdir}"
        fi

        echo "==> Copying ${use_agents}"
        cp ${ROOT}/cache/${use_agents} ${STAGE}/ur-scripts/${use_agents}
    fi

    loops=
}

function copy_agents
{
    # See if there's a specific agents we're supposed to use
    if [[ -f ${ROOT}/build.spec.local ]]; then
        agents_shar=$(cat ${ROOT}/build.spec.local \
            | ${ROOT}/bin/json agents-shar)
    fi
    if [[ -f ${ROOT}/build.spec ]] && [[ -z ${agents_shar} ]]; then
        agents_shar=$(cat ${ROOT}/build.spec \
            | ${ROOT}/bin/json agents-shar)
    fi
    if [[ -z ${agents_shar} ]]; then
        agents_shar="master"
    fi

    get_agents ${agents_shar} ""
}

function copy_datasets
{
    mkdir -p ${STAGE}/datasets
    mkdir -p ${ROOT}/datasets

    datasets_json=
    if [[ -f ${ROOT}/build.spec.local ]]; then
        datasets_json=$(cat ${ROOT}/build.spec.local \
            | ${ROOT}/bin/json "datasets")
    fi
    if [[ -f ${ROOT}/build.spec ]] && [[ -z ${datasets_json} ]]; then
        datasets_json=$(cat ${ROOT}/build.spec \
            | ${ROOT}/bin/json "datasets")
    fi

    [[ -n ${datasets_json} ]] \
        || fatal "Unable to find datasets information in build.spec"

    num_datasets=$(echo "${datasets_json}" | ${ROOT}/bin/json length)
    index=0
    while [[ ${index} -lt ${num_datasets} ]]; do
        name=$(echo "${datasets_json}" | ${ROOT}/bin/json ${index}.name)
        uuid=$(echo "${datasets_json}" | ${ROOT}/bin/json ${index}.uuid)
        headnode_zones=$(echo "${datasets_json}" \
            | ${ROOT}/bin/json ${index}.headnode_zones)
        manifest="${ROOT}/cache/${name}.dsmanifest"

        if [[ ! -f $manifest ]] ; then
            if [[ -f ${ROOT}/datasets/${name}.dsmanifest ]]; then
                cp ${ROOT}/datasets/${name}.dsmanifest ${manifest}
            elif [[ ${HAVE_INTERNET} == "true" ]]; then
                echo "==> Downloading ${name} manifest"

                DATASET_URL="${DSAPI_URL}/datasets/${uuid}"
                (curl ${CURL_OPTS} \
                    -k -o ${manifest} ${DATASET_URL}) \
                    || fatal "Unable to download ${name} manifest"
            else
                fatal "Don't have required '${name}' manifest" \
                    "and can't download (no Internet)"
            fi
        fi

        local path=$(cat ${manifest} | ${ROOT}/bin/json files[0].path)
        local uri=$(cat ${manifest} | ${ROOT}/bin/json files[0].url)
        if [[ -n $(echo "${uri}" | grep "datasets.joyent.com" 2>/dev/null) ]]; then
            # use proper credentials when talking to datasets.joyent.com
            uri="${DSAPI_URL}/datasets/${uuid}/${path}"
        fi
        uri=$(proxy ${uri})
        if [[ -z ${uri} ]]; then
            fatal "Download uri for dataset ${name} not present in manifest"
        fi

        local sha1=$(cat ${manifest} | ${ROOT}/bin/json files[0].sha1)
        copy_dataset ${name} ${uri} ${sha1}
        echo "==> Copying ${name} manifest"
        cp ${manifest} ${STAGE}/datasets/

        # Since create-zone.sh needs to know which dataset it should use to
        # base the headnode zones on, we create these files here, one which
        # contains the filename of the 'smartos' dataset and one that contains
        # its UUID.
        #
        # Note: ${dataset_file} is set by copy_dataset
        if [[ -n ${headnode_zones} && ${headnode_zones} == "true" ]]; then
            echo "${uuid}" > ${STAGE}/datasets/smartos.uuid
            echo "${dataset_file}" > ${STAGE}/datasets/smartos.filename
        fi

        index=$((${index} + 1))
    done
}

# This is temporary, until we have all the SDC datasets at the same place.
# It might be good anyway to add a little check to verify arguments are given.
function copy_dataset
{
  local dataset=$1
  local dataset_uri=$2
  local dataset_sha1=$3

  dataset_file=$(basename ${dataset_uri})
  if [ -e ${ROOT}/cache/${dataset_file} ]; then
    if [[ ${dataset_file} =~ gz$ ]]; then
        if ! gzip -t ${ROOT}/cache/${dataset_file}; then
            echo "==> Corrupt ${dataset_file}, deleting..."
            rm -f ${ROOT}/cache/${dataset_file}
        fi
    elif ! bzip2 -t ${ROOT}/cache/${dataset_file}; then
        echo "==> Corrupt ${dataset_file}, deleting..."
        rm -f ${ROOT}/cache/${dataset_file}
    fi
  fi

  if [[ ! -f ${ROOT}/cache/${dataset_file} ]]; then
      if [[ ${HAVE_INTERNET} == "true" ]]; then
          echo "==> Downloading ${dataset_file}"
          (cd ${ROOT}/cache && curl ${CURL_OPTS} -k \
              -O ${dataset_uri}) \
              || fatal "Unable to download ${dataset_file}"
      else
          fatal "Don't have Internet, and don't have valid " \
              "${dataset_file}. Can't build."
      fi
  fi

  local cached_dataset_sha1=$(${SUM} ${ROOT}/cache/${dataset_file} | awk '{print $1}')
  if [[ ${cached_dataset_sha1} != ${dataset_sha1} ]]; then
    rm -f ${ROOT}/cache/${dataset_file}
    fatal "Corrupt ${dataset_file} (doesn't match sha1 in manifest), deleted! Try build again."
  fi

  echo "==> Copying ${dataset_file}"
  ln ${ROOT}/cache/${dataset_file} ${STAGE}/datasets/${dataset_file}
}

#
# RETURNS (via echo):
#
# The value considered newer between a and b
# If values are same: a
#
function newer_of
{
    a=$1
    b=$2

    if [[ -z ${b} ]]; then
        fatal "is_newer() usage: is_newer \$a \$b"
    fi

    if [[ -z ${a} ]]; then
        echo "${b}" # newer since we have b but not a!
        return 0
    fi

    # Strip off .tar.bz2 or .tbz2 extension (if has one)
    # break into elements separated by - _ or .
    a_array=(`echo "${a}" \
        | sed -e "s/\.tar\.bz2$//" \
        | sed -e "s/\.tbz2$//" \
        | sed -e "s/[-_.]/ /g" | tr -s ' '`)
    b_array=(`echo "${b}" \
        | sed -e "s/\.tar\.bz2$//" \
        | sed -e "s/\.tbz2$//" \
        | sed -e "s/[-_.]/ /g" | tr -s ' '`)

    idx=0
    while [[ -n ${a_array[${idx}]} || -n ${b_array[${idx}]} ]]; do
        a_val=${a_array[${idx}]}
        b_val=${b_array[${idx}]}

        #echo "a[${a_val}] vs b[${b_val}]" >&2

        # if one is empty at this idx, return the other
        if [[ -z ${a_val} ]]; then
            echo "${b}"
            return 0
        fi
        if [[ -z ${b_val} ]]; then
            echo "${a}"
            return 0
        fi

        if [[ ${a_val} == ${b_val} ]]; then
            # same, so do nothing this loop
            true
        elif [[ ${a_val} =~ ^[0-9]+$ && ${b_val} =~ ^[0-9]+$ ]]; then
            # all digits (sort numerically)
            if [[ ${b_val} -gt ${a_val} ]]; then
                echo "${b}"
            else
                echo "${a}"
            fi
            return 0
        else
            # not all digits (sort lexicographically)
            if [[ ${b_val} > ${a_val} ]]; then
                echo "${b}"
            else
                echo "${a}"
            fi
            return 0
        fi

        idx=$((${idx} + 1))
    done
    #echo "COMPARING: '${a}' vs '${b}'" >&2

    echo "${a}"
    return 0
}

function get_latest
{
    target=$1

    [[ -z ${target} ]] && fatal "get_latest(): No target specified."

    # not a file so assume it's a pattern, find the latest
    FS_PATTERN=${target}

    latest=

    if [[ ${HAVE_INTERNET} == "true" ]]; then
        for file in $(curl ${CURL_OPTS} -k -sS ${ASSETS_ROOT}/ \
            | ${GREP} "href=" \
            | cut -d'"' -f2 \
            | ${GREP} "${FS_PATTERN}"); do

            #echo "LATEST BEF: ${latest}"
            latest=$(newer_of "${latest}" "${file}")
            #echo "LATEST NOW: ${latest}"
        done
        [[ $? -ne 0 || -z ${latest} ]] \
            && fatal "Error getting file list for ${FS_PATTERN}"
    else
        for file in $(cd ${ROOT}/cache && ls -1 | ${GREP} "${FS_PATTERN}"); do
            #echo "(cached) LATEST BEFORE: ${latest}"
            latest=$(newer_of "${latest}" "${file}")
            #echo "(cached) LATEST NOW: ${latest}"
        done
    fi

    echo "${latest}"
    return 0
}

function get_fs_tarball
{
    target=$1
    output=$2

    if [[ -z ${output} ]] || [[ ! -d ${output} ]]; then
        fatal "get_fs_tarball(): No output dir specified or not a directory."
    fi

    [[ -z ${target} ]] && fatal "get_fs_tarball(): No target specified."

    zone=$(basename ${output})
    output_filename=${zone}.tar.bz2

    if [[ -f ${target} ]]; then
        # if this is the filename of an existing file, we'll use that
        if [[ ${target} != "${ROOT}/cache/${output_filename}" ]]; then
            cp ${target} ${ROOT}/cache/${output_filename}
        fi
    else
        # not a file so assume it's a pattern, find the latest
        FS_PATTERN=${target}

        filename=$(get_latest ${target})

        if [[ ${HAVE_INTERNET} == "true" ]]; then
            EXISTING_TIMECHECK=
            [[ -f ${ROOT}/cache/${filename} ]] \
                && EXISTING_TIMECHECK="-z ${ROOT}/cache/${filename}"

            (cd ${ROOT}/cache \
                && curl ${CURL_OPTS} -k ${EXISTING_TIMECHECK} \
                -fO ${ASSETS_ROOT}/${filename})
            [[ $? -ne 0 ]] && fatal "Error getting file '${filename}'"

            echo "==> Downloaded ${filename} for ${zone}"

            cp ${ROOT}/cache/${filename} ${ROOT}/cache/${output_filename}
        else
            [[ -z ${filename} ]] \
                && fatal "Don't have Internet and don't have cached " \
                "version of ${FS_PATTERN}"

            echo "==> Using [cached] ${filename} for ${zone}"
            cp ${ROOT}/cache/${filename} ${ROOT}/cache/${output_filename}
        fi
    fi

    if [[ -f ${ROOT}/cache/${output_filename} ]] \
        && ! bzip2 -t ${ROOT}/cache/${output_filename}; then

        fatal "Corrupt file ${output_filename}, please delete or fix and try again."
    elif [[ ! -f ${ROOT}/cache/${output_filename} ]]; then
        fatal "Unable to get file ${output_filename}"
    else
        cp ${ROOT}/cache/${output_filename} ${output}/fs.tar.bz2
    fi
}

function build_fs_tarball
{
    zone_dir=$1
    CHECKOUT_TARGET=$2

    [[ -n ${zone_dir} ]] || fatal "build_fs_tarball(): no zone dir specified."
    [[ -z ${CHECKOUT_TARGET} ]] && CHECKOUT_TARGET='origin/develop'
    export CHECKOUT_TARGET

    zone=$(basename ${zone_dir})

    if [ -x ${zone_dir}/fs.populate ] && \
        [ -d ${zone_dir}/fs.root ]; then

        # do in /tmp because only root can write in mnt
        mkdir -p /tmp/fs.${zone}.$$
        cp -pPR ${zone_dir}/fs.populate ${zone_dir}/fs.root /tmp/fs.${zone}.$$
        rm -rf ${zone_dir}/fs.{populate,root}
        if [[ $REBUILD_FROM_RECIPE == 1 ]]; then
            (cd /tmp/fs.${zone}.$$/fs.root \
                && RECIPE_FILE=$RECIPE ../fs.populate -r\
                && ${TAR} -jcvf ${zone_dir}/fs.tar.bz2 ./)
        else
            (cd /tmp/fs.${zone}.$$/fs.root \
                && RECIPE_FILE=$RECIPE ../fs.populate \
                && ${TAR} -jcvf ${zone_dir}/fs.tar.bz2 ./)
        fi
        if [[ $? -ne 0 ]]; then
            fatal "Failed to populate fs.tar.bz2 for ${zone}"
        fi
    else
        fatal "Can't find fs.populate or fs.root for ${zone}"
    fi
}

function copy_zones
{
    if [[ -n $ZONE_DIR ]]; then
        export ADMINUI_DIR=${ZONE_DIR}/mcp_api_admin
        export CAPI_DIR=${ZONE_DIR}/customers_api
        export BOOTER_DIR=${ZONE_DIR}/booter
        export MAPI_DIR=${ZONE_DIR}/mcp_api_gateway
        export PORTAL_DIR=${ZONE_DIR}/public-web-client
        export CLOUDAPI_DIR=${ZONE_DIR}/cloud-api
        export BILLAPI_DIR=${ZONE_DIR}/billing_api
    fi
    for zone in $(ls ${STAGE}/zones); do

        mkdir -p ${STAGE}/zones/${zone}

        local override_var=$(echo $zone | tr '[:lower:]' '[:upper:]')_FS
        override=$(eval echo \$${override_var})
        FS_TARBALL=
        tarball_pattern=
        target_checkout=

        if [[ ${HAVE_INTERNET} != "true" ]]; then
            override=${ROOT}/cache/${zone}.tar.bz2
        fi

        if [[ -f ${ROOT}/build.spec ]] && [[ -z ${tarball_pattern} ]]; then
            tarball_pattern=$(cat ${ROOT}/build.spec \
                | ${ROOT}/bin/json "${zone}-tarball")
            target_checkout=$(cat ${ROOT}/build.spec \
                | ${ROOT}/bin/json "${zone}-checkout")
        fi
        if [[ -f ${ROOT}/build.spec.local ]]; then
            tarball_pattern=$(cat ${ROOT}/build.spec.local \
                | ${ROOT}/bin/json "${zone}-tarball")
            target_checkout=$(cat ${ROOT}/build.spec.local \
                | ${ROOT}/bin/json "${zone}-checkout")
        fi


        if [[ -z ${target_checkout} ]]; then
            target_checkout=$GIT_BRANCH
        fi

        # Symlinks aren't supported on pcfs, so we copy the files
        if [[ -L ${ROOT}/zones/${zone}/backup ]]; then
            rm ${STAGE}/zones/${zone}/backup
            cp ${ROOT}/zones/${zone}/backup ${STAGE}/zones/${zone}/backup
        fi
        if [[ -L ${ROOT}/zones/${zone}/restore ]]; then
            rm ${STAGE}/zones/${zone}/restore
            cp ${ROOT}/zones/${zone}/restore ${STAGE}/zones/${zone}/restore
        fi

        if [[ -n ${override} ]]; then
            # If there was an override, use that withi highest priority
            get_fs_tarball ${override} ${STAGE}/zones/${zone}
        elif [[ -n ${tarball_pattern} ]]; then
            # No override, so find latest that matches tarball_pattern
            get_fs_tarball ${tarball_pattern} ${STAGE}/zones/${zone}
        elif [ -x ${STAGE}/zones/${zone}/fs.populate ] && \
            [ -d ${STAGE}/zones/${zone}/fs.root ]; then

            build_fs_tarball ${STAGE}/zones/${zone} ${target_checkout}
        fi

        if [[ ! -f ${STAGE}/zones/${zone}/fs.tar.bz2 ]];then
            fatal "Unable to find or build fs.tar.bz2 for ${zone}"
        else
            # Keep a copy in cache so we can build next time with no Internet
            cp ${STAGE}/zones/${zone}/fs.tar.bz2 \
                ${ROOT}/cache/${zone}.tar.bz2
        fi

        if [[ "${IMG_TYPE}" == "coal" ]]; then
            echo "IMG_TYPE=coal" >> ${STAGE}/zones/${zone}/zoneconfig
        fi
    done

}

function copy_devtools
{
    if [[ "${IMG_TYPE}" == "coal" ]]; then
        echo "==> Copying in devtools"
        cp -r ${ROOT}/devtools ${STAGE}/devtools
    fi
}

function copy_hvm_files
{
    if [[ -f "${ROOT}/build.spec" ]]; then
        if [[ -z ${BUILD_HVM} ]]; then
            BUILD_HVM=$(cat ${ROOT}/build.spec \
                | ${ROOT}/bin/json build-hvm)
        fi
        if [[ -z ${HVM_PLATFORM_RELEASE} ]]; then
            HVM_PLATFORM_RELEASE=$(cat ${ROOT}/build.spec \
                | ${ROOT}/bin/json hvm-platform-release)
        fi
        if [[ -z ${HVM_AGENTS_SHAR} ]]; then
            HVM_AGENTS_SHAR=$(cat ${ROOT}/build.spec \
                | ${ROOT}/bin/json hvm-agents-shar)
        fi
        if [[ -z ${HVM_SUBDIR} ]]; then
            HVM_SUBDIR=$(cat ${ROOT}/build.spec \
                | ${ROOT}/bin/json hvm-subdir)
        fi
    fi
    if [[ -f "${ROOT}/build.spec.local" ]]; then
        BUILD_HVM=$(cat ${ROOT}/build.spec.local \
            | ${ROOT}/bin/json build-hvm)
        HVM_PLATFORM_RELEASE=$(cat ${ROOT}/build.spec.local \
            | ${ROOT}/bin/json hvm-platform-release)
        HVM_AGENTS_SHAR=$(cat ${ROOT}/build.spec.local \
            | ${ROOT}/bin/json hvm-agents-shar)
        HVM_SUBDIR=$(cat ${ROOT}/build.spec.local \
            | ${ROOT}/bin/json hvm-subdir)
    fi

    if [[ -z ${BUILD_HVM} ]]; then
        BUILD_HVM="false"
    fi
    if [[ -z ${HVM_AGENTS_SHAR} ]]; then
        HVM_AGENTS_SHAR="hvm"
    fi
    if [[ -z ${HVM_PLATFORM_RELEASE} ]]; then
        HVM_PLATFORM_RELEASE="hvm"
    fi

    if [[ ${BUILD_HVM} == "true" ]]; then
        echo "HAVE_HVM=true" >> ${STAGE}/zones/adminui/zoneconfig
        get_agents ${HVM_AGENTS_SHAR} "${HVM_SUBDIR}"
        copy_platform "${HVM_PLATFORM_FILE}" "${HVM_PLATFORM_RELEASE}" "false" "${HVM_SUBDIR}"
    fi
}

function copy_webinfo
{
    if [[ -f "${ROOT}/build.spec" ]]; then
        WEBINFO_CHECKOUT=$(cat ${ROOT}/build.spec \
            | ${ROOT}/bin/json sdc-webinfo-checkout)
    fi
    if [[ -f "${ROOT}/build.spec.local" ]]; then
        WEBINFO_CHECKOUT=$(cat ${ROOT}/build.spec.local \
            | ${ROOT}/bin/json sdc-webinfo-checkout)
    fi

    if [[ -z $WEBINFO_CHECKOUT ]]; then
        WEBINFO_CHECKOUT="origin/master"
    fi
    ( mkdir -p /tmp/$$.webinfo && cd /tmp/$$.webinfo && \
        git clone git@git.joyent.com:sdc-webinfo.git webinfo && \
        cd webinfo && git checkout $WEBINFO_CHECKOUT && cd .. && \
        $TAR -cf ${STAGE}/webinfo.tar --exclude .git webinfo )
        
}

function create_upgrade
{
    rm -rf ${ROOT}/cache/upgrade
    mkdir -p ${ROOT}/cache/upgrade/usbkey
    cp ${ROOT}/bin/upgrade.sh ${ROOT}/cache/upgrade/upgrade.sh
    cp ${STAGE}/config ${STAGE}/config.default
    chmod 755 ${ROOT}/cache/upgrade/upgrade.sh
    (cd ${STAGE} \
        && env GZIP=-9 \
        ${TAR} -zcf ${ROOT}/cache/upgrade/usbkey/upgrade-$(git describe).tgz \
        boot/grub/menu.lst.tmpl \
        config.default \
        data \
        datasets/smartos* \
        rc \
        scripts \
        ur-scripts \
        zoneinit \
        zones \
    )

    mkdir -p ${ROOT}/cache/upgrade/platform
    cp ${USING_PLATFORM} ${ROOT}/cache/upgrade/platform
}

function copy_to_mount
{
    echo "${THIS_VERSION}" > ${STAGE}/version
    (cd ${STAGE} && ${TAR} ${TAR_ROOT} -cf - ./) \
        | (cd ${MNT_DIR} && ${SUCMD} ${TAR} --no-same-owner -xvf -) \
        || fatal "Unable to copy files to mount"
}

function pack_upgrade
{
    echo "${THIS_VERSION}" > ${ROOT}/cache/upgrade/VERSION

    (cd ${ROOT}/cache \
        && GZIP=-9 ${TAR} -zcvf ${ROOT}/upgrade-${THIS_VERSION}.tgz upgrade)
}

# Main()

check_nodejs
check_npm
test_rootperms
create_directories
load_buildspec
copy_base
copy_pkgsrc
copy_platform "${PLATFORM_FILE}" "${PLATFORM_RELEASE}" "true" "${PLATFORM_SUBDIR}"
copy_agents
copy_datasets
copy_zones
copy_devtools
copy_hvm_files
copy_webinfo

$(mv $RECIPE ${STAGE}/recipe)
if [[ -z ${ONLY_UPGRADE} ]]; then
    unpack_image
    add_manifests
    mount_image
    trap 'cleanup' EXIT
    copy_to_mount
    cleanup
    create_output
else
    create_upgrade
    pack_upgrade
fi

# Unfortunately the log contains a whole bunch of progress updates,
# clean that up.
if [[ -f ${LOGFILE} ]]; then
    cat ${LOGFILE} | ${GREP} -v "
" > ${LOGFILE}.tmp \
    && mv ${LOGFILE}.tmp ${LOGFILE}
fi

if [ ${ERROR} -ne 0 ]; then
    fatal "==> SOMETHING WENT WRONG! ERROR: ${ERROR}"
fi

echo "==> DONE"

exit 0
